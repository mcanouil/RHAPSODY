---
params:
  cohort_name: "Cohort Name"
  author_name: "Firstname LASTNAME"
  opal_credentials: "opal_credentials.txt"
  vcf_input_directory: "./vcfs"
  imputation_quality_tag: "INFO"
  vcftools_binary_path: "/usr/local/bin"
  output_directory: "./"
  analysis_step: 1
  format_vcfs: TRUE
  variants_analysis: TRUE
  chunk_size: 1000
  exclude_X: TRUE
  genomic_component: NULL
  n_cpu: 2
  install_packages: FALSE
  echo: FALSE
  warning: FALSE
  message: FALSE
  debug: FALSE
title: "RHAPSODY WP3 Pre-Diabetes Analysis Plan (Version 1.2.24)"
subtitle: '`r params$cohort_name`'
author: '`r params$author_name`'
date: '`r format(Sys.Date(), "%d %B %Y")`'
monofont: "Source Code Pro"
monofontoptions: "Scale=0.7"
output:
  html_document:
    keep_md: false
    theme: simplex
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
    fig_width: 6.3
    fig_height: 4.7
    number_sections: true
    self_contained: true
    mathjax: default
    df_print: kable
editor_options: 
  chunk_output_type: console
---

<!-- Author - Mickaël Canouil, Ph.D. -->

```{r setup, include = FALSE, echo = FALSE}
options(stringsAsFactors = FALSE)

if (params$install_packages) {
  # Install R packages and load them
  if (!all(c("udunits2", "units", "devtools", "caTools")%in%rownames(utils::installed.packages()))) {
    utils::install.packages(
      pkgs = setdiff(c("udunits2", "units", "devtools", "caTools"), rownames(utils::installed.packages())),
      configure.args = "--with-udunits2-lib=/usr/local/lib",
      quiet = TRUE,
      repos = c("http://cran.us.r-project.org", "https://cran.rstudio.com/")
    )
  }
  if (!all(c("opal")%in%rownames(utils::installed.packages()))) {
    utils::install.packages(
      pkgs = "opal", 
      repos = c("https://cran.obiba.org", "https://cran.rstudio.com/"), 
      dependencies = TRUE, 
      quiet = TRUE
    )
  }
  list_packages <- read.table(
    col.names = c("package", "version"), 
    text = '"acepack"	"1.4.1"
    "assertthat"	"0.2.0"
    "backports"	"1.1.1"
    "base64enc"	"0.1-3"
    "BH"	"1.66.0-1"
    "bindr"	"0.1.1"
    "plogr"	"0.2.0"
    "bindrcpp"	"0.2.2"
    "bitops"	"1.0-6"
    "brew"	"1.0-6"
    "foreign"	"0.8-69"
    "mnormt"	"1.5-5"
    "lattice"	"0.20-35"
    "nlme"	"3.1-131"
    "psych"	"1.7.8"
    "plyr"	"1.8.4"
    "pkgconfig"	"2.0.1"
    "utf8"	"1.1.3"
    "pillar"	"1.2.2"
    "tibble"	"1.4.2"
    "purrr"	"0.2.4"
    "tidyselect"	"0.2.4"
    "dplyr"	"0.7.5"
    "reshape2"	"1.4.3"
    "tidyr"	"0.8.1"
    "broom"	"0.4.4"
    "callr"	"1.0.0"
    "rematch"	"1.0.1"
    "cellranger"	"1.1.0"
    "checkmate"	"1.8.5"
    "cli"	"1.0.0"
    "cluster"	"2.0.6"
    "colorspace"	"1.3-2"
    "compiler"	"3.4.2"
    "RColorBrewer"	"1.1-2"
    "dichromat"	"2.0-0"
    "munsell"	"0.4.3"
    "labeling"	"0.3"
    "viridisLite"	"0.3.0"
    "scales"	"0.5.0"
    "gtable"	"0.2.0"
    "lazyeval"	"0.2.1"
    "ggplot2"	"2.2.1"
    "cowplot"	"0.9.1"
    "crayon"	"1.3.4"
    "curl"	"3.0"
    "data.table"	"1.10.4-3"
    "downloader"	"0.4"
    "htmlwidgets"	"0.9"
    "Matrix"	"1.2-12"
    "irlba"	"2.3.1"
    "igraph"	"1.1.2"
    "influenceR"	"0.1.0"
    "Rook"	"1.1-1"
    "XML"	"3.98-1.9"
    "rgexf"	"0.15.3"
    "gridExtra"	"2.3"
    "viridis"	"0.5.1"
    "visNetwork"	"2.0.1"
    "hms"	"0.4.2"
    "readr"	"1.1.1"
    "DiagrammeR"	"0.9.2"
    "data.tree"	"0.7.4"
    "DBI"	"0.7"
    "dbplyr"	"1.2.1"
    "devtools"	"1.13.5"
    "digest"	"0.6.15"
    "evaluate"	"0.10.1"
    "forcats"	"0.3.0"
    "Formula"	"1.2-2"
    "git2r"	"0.19.0"
    "glue"	"1.2.0"
    "graphics"	"3.4.2"
    "grDevices"	"3.4.2"
    "grid"	"3.4.2"
    "haven"	"1.1.1"
    "highr"	"0.6"
    "rpart"	"4.1-11"
    "latticeExtra"	"0.6-28"
    "survival"	"2.41-3"
    "nnet"	"7.3-12"
    "htmlTable"	"1.11.0"
    "Hmisc"	"4.1-1"
    "htmltools"	"0.3.6"
    "httr"	"1.3.1"
    "jsonlite"	"1.5"
    "xml2"	"1.2.0"
    "selectr"	"0.3-1"
    "rvest"	"0.3.2"
    "kableExtra"	"0.6.1"
    "knitr"	"1.20"
    "minqa"	"1.2.4"
    "nloptr"	"1.0.4"
    "RcppEigen"	"0.3.3.3.1"
    "lme4"	"1.1-14"
    "numDeriv"	"2016.8-1"
    "lmerTest"	"3.0-1"
    "lubridate"	"1.7.4"
    "magrittr"	"1.5"
    "markdown"	"0.8"
    "MASS"	"7.3-47"
    "memoise"	"1.1.0"
    "methods"	"3.4.2"
    "mgcv"	"1.8-22"
    "mime"	"0.5"
    "modelr"	"0.1.1"
    "openssl"	"0.9.9"
    "parallel"	"3.4.2"
    "R6"	"2.2.2"
    "Rcpp"	"0.12.17"
    "RCurl"	"1.95-4.8"
    "readxl"	"1.1.0"
    "reprex"	"0.1.2"
    "rjson"	"0.2.15"
    "rlang"	"0.2.1"
    "rmarkdown"	"1.9"
    "rprojroot"	"1.2"
    "rstudioapi"	"0.7"
    "splines"	"3.4.2"
    "stats"	"3.4.2"
    "stringi"	"1.2.3"
    "stringr"	"1.3.1"
    "tools"	"3.4.2"
    "utils"	"3.4.2"
    "whisker"	"0.3-2"
    "withr"	"2.1.2"
    "writexl"	"0.2"
    "yaml"	"2.1.15"
    "tidyverse" "1.2.1"
    "ggsignif" "0.4.0"
    "ggrepel" "0.8.0"
    "ggsci" "2.9"
    "polynom" "1.3-9"
    "ggpubr" "0.2"'
  )
  list_packages[, "local_version"] <- sapply(list_packages[, "package"], utils::packageDescription, fields = "Version")
  list_packages[, "local_version"] <- ifelse(is.na(list_packages[, "local_version"]), "", list_packages[, "local_version"])
  list_packages <- list_packages[list_packages[, "local_version"]!=list_packages[, "version"], ]
  if (nrow(list_packages)>0) {
    mapply(
      x = list_packages[, "package"], 
      y = list_packages[, "version"], 
      FUN = function(x, y) {
        devtools::install_version( 
          package = x,
          version = as.character(y),
          repos = c("http://cran.us.r-project.org", "https://cran.rstudio.com/"),
          dependencies = FALSE,
          quiet = FALSE,
          upgrade = "never"
        )
      }
    )
  }
}

list_packages <- c(
  "tidyverse",
  "devtools", "parallel", "grid", "scales",
  "broom", "viridis", "readxl", "writexl",
  "cowplot", "knitr", "kableExtra", "lme4",
  "lmerTest", "Hmisc", "data.tree", "opal"
)
invisible(sapply(X = list_packages, FUN = library, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE))


check_steps <- function(params, max) {
  out <- as.list(rep(FALSE, 7))
  names(out) <- paste0("step_", seq_len(7))
  out[paste0("step_", seq_len(params$analysis_step))] <- TRUE
  out
}
params_steps <- check_steps(params)

knitr::opts_chunk$set(
  cache = FALSE,
  echo = params$echo,
  warning = params$warning,
  error = TRUE,
  message = params$message,
  include = TRUE,
  tidy = FALSE,
  crop = TRUE,
  autodep = TRUE,
  fig.align = "center",
  fig.pos = "!H",
  dpi = 120,
  size = "small", 
  results = "asis"
)

# Code to resize font size of R code chunks output according to "size" option (only LATEX)
if (knitr:::is_latex_output()) {
  def.chunk.hook <- knitr::knit_hooks$get("chunk")
  knitr::knit_hooks$set(chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(
      options$size != "normalsize", 
      paste0("\\", options$size, "\n\n", x, "\n\n \\normalsize"), 
      x
    )
  })
}

ggplot2::theme_set(ggplot2::theme_light(base_size = 12))
```

```{r check_parameters, echo = FALSE}
if (!file.exists(params$opal_credentials)) {
  stop(paste0('File "', params$opal_credentials, '" doesn\'t exist!\nPlease check the settings.'))
}
if (!file.exists(paste0(params$vcftools_binary_path, "/vcftools"))) {
  stop(paste0('Please check the path to vcftools: "', params$vcftools_binary_path, '" seems to be incorrect.'))
}
```

```{r define_r_functions, include = FALSE, echo = FALSE}
format_pval <- function (x, thresh = 10^-2, digits = 3, eps = 1e-50) {
  ifelse(
    x>=thresh, 
    Hmisc::format.pval(x, digits = digits, eps = eps, nsmall = digits), 
    base::format.pval(x, digits = digits, eps = eps, scientific = TRUE, nsmall = digits)
  )
}

pretty_kable <- function(
  data,
  font_size = 12,
  format.args = list(scientific = -1, digits = 3, big.mark = ","),
  col.names = NA,
  pval_cols = NULL,
  ...
) {
  if (!is.null(pval_cols)) {
    data[, pval_cols] <- format_pval(
      x = data[, pval_cols],
      digits = format.args$digits
    )
  }
  colnames(data) <- Hmisc::capitalize(colnames(data))
  if (knitr:::is_latex_output()) {
    options(knitr.table.format = "latex")
    knitr::kable(x = data, booktabs = TRUE, format.args = format.args, col.names = col.names, ...) %>%
      kableExtra::kable_styling(
        latex_options = c("hold_position"),
        full_width = FALSE,
        position = "center",
        font_size = font_size
      )
  } else {
    options(knitr.table.format = "html")
    knitr::kable(x = data, format.args = format.args, col.names = col.names, ...) %>%
      kableExtra::kable_styling(
        bootstrap_options = c("striped", "hover", "condensed", "responsive"),
        full_width = TRUE,
        position = "center",
        font_size = font_size
      )
  }
}

# reference table to convert HbA1c from percentage to mmol/mol
convert_hba1c <- function(x, unitFrom = "%") {
  if (unitFrom == "%") {
    hba1c_unit_table <- structure(list(
      V1 = c(
        10L, 12L, 14L, 16L, 18L, 20L, 22L, 24L,
        26L, 28L, 30L, 32L, 34L, 36L, 38L, 40L, 42L, 44L, 46L, 48L, 50L,
        52L, 54L, 56L, 58L, 60L, 62L, 64L, 66L, 68L, 70L, 72L, 74L, 76L,
        78L, 80L, 82L, 84L, 86L, 88L, 90L, 92L, 94L, 96L, 98L, 100L,
        102L, 104L, 106L, 108L, 110L, 112L, 114L, 116L, 118L, 120L, 122L,
        124L, 126L, 128L, 130L, 132L, 134L, 136L, 138L, 140L, 142L, 144L,
        146L, 148L, 150L, 152L, 154L, 156L, 158L, 160L, 162L, 164L, 166L,
        168L, 170L, 172L, 174L, 176L, 178L, 180L, 182L, 184L, 186L, 188L,
        190L, 192L, 194L, 196L, 198L, 200L, 202L, 204L, 208L, 210L
      ),
      V2 = c(
        3.1, 3.2, 3.4, 3.6, 3.8, 4, 4.2, 4.3, 4.5, 4.7, 4.9,
        5.1, 5.3, 5.4, 5.6, 5.8, 6, 6.2, 6.4, 6.5, 6.7, 6.9, 7.1,
        7.3, 7.5, 7.6, 7.8, 8, 8.2, 8.4, 8.6, 8.7, 8.9, 9.1, 9.3,
        9.5, 9.7, 9.8, 10, 10.2, 10.4, 10.6, 10.8, 10.9, 11.1, 11.3,
        11.5, 11.7, 11.8, 12, 12.2, 12.4, 12.6, 12.8, 12.9, 13.1,
        13.3, 13.5, 13.7, 13.9, 14, 14.2, 14.4, 14.6, 14.8, 15, 15.1,
        15.3, 15.5, 15.7, 15.9, 16.1, 16.2, 16.4, 16.6, 16.8, 17,
        17.2, 17.3, 17.5, 17.7, 17.9, 18.1, 18.3, 18.4, 18.6, 18.8,
        19, 19.2, 19.4, 19.5, 19.7, 19.9, 20.1, 20.3, 20.4, 20.6,
        20.8, 21, 21.2
      )
    ), .Names = c("V1", "V2"), class = "data.frame", row.names = c(NA, -100L))
    hba1c_model <- coef(lm(V1~V2, data = hba1c_unit_table))
    x <- sapply(x, function(y) round(sum(hba1c_model * c(1, y))))
  }
  x
}

# function to convert g/l to mmol/l
convert_2mmoll <- function(x, from = "g/l") {
  switch(EXPR = tolower(from),
    "g/l" = {x / 0.18},
    "mg/l" = {x / 0.18 / 100},
    "mmol/l" = {x},
    stop("Please check Units: g/l, g/L, mg/l, mg/L, mmol/l or mmol/L!")
  )
}

# function to convert "Vital Signs" (VS) OPAL table (CDISC) to "long format"
format_vs <- function(data) {
  data <- dplyr::mutate(
    .data = data,
    KEY_FACTOR = paste(DOMAIN, STUDYID, SUBJID, VISIT, sep = "_")
  )
  rownames(data) <- NULL
  
  descriptive_data <- dplyr::distinct(.data = dplyr::select(.data = data, DOMAIN, STUDYID, VSORRESU, VSTEST, VSTESTCD))
  
  if (!"VSTPTNUM"%in%colnames(data)) {
    data <- dplyr::mutate(.data = data, VSTPTNUM = NA)
  }
  if (!"VSTPT"%in%colnames(data)) {
    data <- dplyr::mutate(.data = data, VSTPT = NA)
  }
  
  data_values <- dplyr::full_join(
    x = dplyr::full_join(
      x = data %>%
        subset(is.na(VSTPTNUM)) %>%
        dplyr::select(KEY_FACTOR, VSORRES, VSTESTCD) %>%
        tidyr::spread(key = "VSTESTCD", value = "VSORRES"),
      y = data %>%
        subset(!is.na(VSTPTNUM)) %>%
        dplyr::select(KEY_FACTOR, VSORRES, VSTESTCD, VSTPTNUM) %>%
        dplyr::mutate(KEY_MEASURES = paste(VSTESTCD, VSTPTNUM, sep = "_")) %>%
        dplyr::select(KEY_FACTOR, KEY_MEASURES, VSORRES) %>%
        tidyr::spread(key = "KEY_MEASURES", value = "VSORRES"),
      by = c("KEY_FACTOR" = "KEY_FACTOR")
    ),
    y = data %>%
      dplyr::select(-c(VSORRES, VSTPT, VSTPTNUM, VSORRESU, VSTEST, VSTESTCD)) %>%
      dplyr::distinct(),
    by = c("KEY_FACTOR" = "KEY_FACTOR")
  ) %>%
    dplyr::mutate(
      VISIT = factor(
        x = VISIT,
        levels = c(
          "BASELINE", 
          sort(grep("VISIT", unique(VISIT), value = TRUE)), 
          "LAST"
        )
      )
    ) %>%
    dplyr::group_by(DOMAIN, STUDYID, SUBJID) %>%
    dplyr::arrange(VISIT) %>%
    dplyr::select(-KEY_FACTOR) %>%
    data.frame()
  
  list(data = data_values, annotation = descriptive_data)
}

# function to convert "Laboratory Measurements" (LB) OPAL table (CDISC) to "long format"
format_lb <- function(data) {
  check_multiple_hba1c <- data %>% 
    dplyr::select(LBTESTCD, LBORRESU) %>% 
    dplyr::filter(LBTESTCD=="HBA1C") %>% 
    dplyr::distinct()
  if (nrow(check_multiple_hba1c)>1) {
    if (any(grepl("%", check_multiple_hba1c[["LBORRESU"]]))) {
      data <- data %>% 
        dplyr::filter(
          !(LBTESTCD=="HBA1C" & LBORRESU %in% setdiff(check_multiple_hba1c[["LBORRESU"]], "%"))
        )
    } else {
       data <- data %>% 
        dplyr::filter(
          !(LBTESTCD=="HBA1C" & LBORRESU %in% setdiff(check_multiple_hba1c[["LBORRESU"]], "mmol/mol"))
        )
    }
  }
  
  data <- dplyr::mutate(
    .data = data,
    LBFAST = if ("LBFAST" %in% colnames(data)) LBFAST else NA,
    LBTPTNUM = if ("LBTPTNUM" %in% colnames(data)) LBTPTNUM else NA,
    LBTPTNUM = ifelse(LBTESTCD == "GLUC" & is.na(LBTPTNUM), 0, LBTPTNUM),
    KEY_FACTOR = paste(DOMAIN, STUDYID, SUBJID, VISIT, sep = "_")
  )
  rownames(data) <- NULL

  descriptive_variables <- c(
    "LBORRESU", "LBTEST", "LBTESTCD", "LBSPEC", 
    "LBCAT", "LBMETHOD", "LBTPT", "LBTPTNUM", "AGCAT"
  )
  
  descriptive_data <- data %>%
    dplyr::select(intersect(c("DOMAIN", "STUDYID", !!descriptive_variables), colnames(.))) %>%
    dplyr::distinct() %>%
    dplyr::mutate(
      KEY_MEASURES = paste(LBTESTCD, LBSPEC, LBCAT, LBTPTNUM, sep = "_")
    )

  data_values <- dplyr::full_join(
    x = (data %>%
      dplyr::select(KEY_FACTOR, LBORRES, LBTESTCD, LBSPEC, LBCAT, LBTPTNUM) %>%
      dplyr::mutate(
        KEY_MEASURES = paste(LBTESTCD, LBSPEC, LBCAT, LBTPTNUM, sep = "_")
      ) %>%
      dplyr::select(KEY_FACTOR, KEY_MEASURES, LBORRES) %>%
      tidyr::spread(key = "KEY_MEASURES", value = "LBORRES")),
    y = (data %>%
      dplyr::select(LBDTC, SUBJID, VISIT, DOMAIN, STUDYID, LBFAST, KEY_FACTOR) %>%
      dplyr::distinct()),
    by = c("KEY_FACTOR" = "KEY_FACTOR")
  ) %>%
    dplyr::mutate(
      VISIT = factor(
        x = VISIT,
        levels = c(
          "BASELINE", 
          sort(grep("VISIT", unique(VISIT), value = TRUE)), 
          "LAST"
        )
      )
    ) %>%
    dplyr::group_by(DOMAIN, STUDYID, SUBJID) %>%
    dplyr::arrange(VISIT) %>%
    dplyr::select(-KEY_FACTOR) %>%
    data.frame()

  list(data = data_values, annotation = descriptive_data)
}

# function to compute bmi if not available
compute_bmi <- function(data) {
  if (!"BMI"%in%data$annotation[["VSTESTCD"]]) {
    weight_unit <- data$annotation %>% 
      dplyr::filter(VSTESTCD == "WEIGHT") %>% 
      dplyr::select(VSORRESU) %>% 
      unlist()
    convert_weight_unit <- switch(
      EXPR = weight_unit,
      "kg" = {function(x) x},
      "lb" = {function(x) x * 0.45359237}
    )
    
    height_unit <- data$annotation %>% 
      dplyr::filter(VSTESTCD=="HEIGHT") %>% 
      dplyr::select(VSORRESU) %>% 
      unlist()
    convert_height_unit <- switch(
      EXPR = height_unit,
      "cm" = {function(x) x / 100},
      "m" = {function(x) x},
      "in" = {function(x) (x * 2.54) / 100}
    )
    
    data$data <- dplyr::mutate(
      .data = data$data,
      BMI = convert_weight_unit(WEIGHT) / convert_height_unit(HEIGHT)
    )
    default_CDISC_BMI <- structure(
      list(
        DOMAIN = "VS", 
        STUDYID = unique(data$annotation[["STUDYID"]]), 
        VSORRESU = "kg/m2", 
        VSTEST = "Body Mass Index", 
        VSTESTCD = "BMI"
      ), 
      .Names = c("DOMAIN",  "STUDYID", "VSORRESU", "VSTEST", "VSTESTCD"), 
      row.names = 1L, 
      class = "data.frame"
    )
    data$annotation <- dplyr::bind_rows(data$annotation, default_CDISC_BMI)
  }
  data
}

# function to extract results from lmer functions in a tidy way (one row)
tidy_lmer <- function(x) {
  res <- data.frame(coefficients(summary(x)), check.names = FALSE, stringsAsFactors = FALSE)
  colnames(res) <- c("ESTIMATE", "SE", "DF", "STAT", "PVALUE")
  res[, "Term"] <- gsub(".*Intercept.*", "Intercept", rownames(res))
  res <- tidyr::gather(data = res, key = "Variable", value = "Value", -"Term")
  rownames(res) <- paste(res[, "Term"], res[, "Variable"], sep = "_")
  data.frame(t(res[, "Value", drop = FALSE]), check.names = FALSE, stringsAsFactors = FALSE)
}

# extract residuals from mixed model and list samples with median plus/minus 3*IQR
get_residuals_outliers <- function(x) {
  dplyr::filter( 
    .data = dplyr::mutate(
      .data = x@frame,
      residuals = residuals(x),
      r_iqr = 3 * IQR(residuals),
      r_median = median(residuals),
      left = r_median - r_iqr,
      right = r_median + r_iqr
    ),
    residuals<left | residuals>right
  )[["SUBJID"]]
}

# function to compute mean and sd, then paste results for output
compute_mean_sd <- function(x, digits = 2) {
  paste0(
    round(mean(x, na.rm = TRUE), digits = digits),
    " (",
    round(sd(x, na.rm = TRUE), digits = digits),
    ")"
  )
}
```

```{r logo, echo = FALSE, out.width = "300px", eval = file.exists("utils/RHAPSODY_Logo_WEB_Color.png")}
knitr::include_graphics(path = "utils/RHAPSODY_Logo_WEB_Color.png")
```

# Goal

Combining two-point and multi-point longitudinal data from prediabetes cohorts to estimate the effects of genetic biomarkers on glycaemic trait rate change

## Key question to answer

Do genetic variants show association with the trait rate change?

## Summary

This analysis plan details the data preparation and analyses steps for detecting SNP associations with quantitative trait rate change (determined by modelling time x single nucleotide polymorphism (SNP) interactions) in RHAPSODY (Prediabetes cohorts within WP3: MDC, BOTNIA, ADDITION-PRO, DESIR, CoLAUS).

For  each genetic variant, we will seek to estimate the average linear effect of a given SNP over time (SNP effect) and SNP effect on the rate change (SNPxtime); thus, we will address the question of whether a given SNP is associated with the linear trajectory of the trait from baseline through follow-up. Non-linear trajectories may exist but because the available data is relatively sparse, we will not seek to model non-linear patterns. 

We will focus on the following glycaemic traits as outcomes: fasting glucose (FG), 2h glucose (2hG) and HbA1c. 

Results from analyses from different cohorts will be combined in two meta-analyses: one including all cohorts with data available from at least two time-points, and the second including only those cohorts with data available for at least three time-points. 

The latter analysis will yield a more precise estimation of longitudinal trajectories than when data from only two time-points are available. 


# Quality control of phenotype data

## Summary

1.  Make sure measured biomarker data are in the same units across all the cohorts.  
Fasting and 2-h plasma glucose in mmol/l and HbA1c in mmol/mol.
2.  For fasting and 2-h glucose, ensure only those participants who are fasted for at least 8-h are included.
3.  Exclusion of participants with data available for only one time-point.  
Only individuals with at least 2 observations should be included in the analysis.
4.  Exclusion of participants with diabetes at baseline.  
As we will focus on prediabetes (and also include participants with normoglycaemia), prevalent cases of diabetes at baseline using ADA diagnostic criteria must be excluded; this applies to participants with known diabetes as well as those with screen-detected diabetes at baseline.  
Diagnostic criteria for diabetes ([ADA criteria; Diabetes Care 2015 Jan; 38, Supplement 1](http://care.diabetesjournals.org/content/suppl/2014/12/23/38.Supplement_1.DC1/January_Supplement_Combined_Final.6-99.pdf)):
    * Fasting plasma glucose $\geq$ 7.0 mmol/l (126 mg/dl) or
    * 2h plasma glucose $\geq$ 11.1 mmol/l (200 mg/dl) or
    * HbA1c $\geq$ 48 mmol/mol (6.5 %). 
5.  Exclusion of participants developing diabetes during the study time:
    * Individuals developing diabetes during the follow up and with no available information on medication  should be excluded.
    * Individuals with Type I Diabetes or/and INSULIN and ANALOGUES treatment.
6.  Additional exclusion based on model diagnostics (see preliminary modelling for details)


```{r open_opal_connection, eval = params_steps$step_1, results = ifelse(params$echo, "asis", "hide")}
cat("\n# Load data from OPAL node\n\n")
cat("\n## Open connection to OPAL node\n\n")

opal_credentials <- as.data.frame(t(
  utils::read.table(
    file = params$opal_credentials, 
    stringsAsFactors = FALSE, 
    row.names = c("opal_server", "opal_login", "opal_password")
  )
), stringsAsFactors = FALSE)

o <- opal::opal.login(
  username = opal_credentials$opal_login,
  password = opal_credentials$opal_password,
  url = opal_credentials$opal_server
)

cat("\n## Import table from OPAL node to local R session\n\n")
# Available tables in OPAL (Check RHAPSODY/CDISC documentation for details)
available_tables <- intersect(opal::opal.datasources(opal = o)[[1]]$table, c("DM", "VS", "LB", "APMH", "CM", "MH"))

for (itable in available_tables) {
  opal::opal.assign(opal = o, symbol = itable, value = paste0("rhapsody.", itable))
  assign(x = itable, value = opal::opal.execute(o, itable))
}

cat("\n## Close connection to OPAL node and clean workspace\n\n")
opal.logout(o)
rm(list = c("o", "itable", "available_tables"))

cat("\n## Convert CDSIC to long format\n\n")
vs_tidy <- format_vs(data = VS)
vs_tidy <- compute_bmi(data = vs_tidy)
lb_tidy <- format_lb(data = LB)
# To check if LB/VS are correctly formatted (should return TRUE)
# n_LB <- LB %>% 
#   dplyr::select(STUDYID, SUBJID, VISIT) %>% 
#   dplyr::distinct() %>% 
#   dplyr::count(STUDYID, SUBJID) %>% 
#   dplyr::summarise(n = sum(n)) %>% 
#   unlist()
# 
# n_VS <- VS %>% 
#   dplyr::select(STUDYID, SUBJID, VISIT) %>% 
#   dplyr::distinct() %>% 
#   dplyr::count(STUDYID, SUBJID) %>% 
#   dplyr::summarise(n = sum(n)) %>% 
#   unlist() 
# 
# (all(c(nrow(lb_tidy$data), n_LB, nrow(vs_tidy$data), n_VS) == nrow(DMVSLB)))

DMVSLB <- dplyr::full_join(
  x = dplyr::select(.data = dplyr::mutate(.data = DM, VISIT = "BASELINE"), -DOMAIN),
  y = dplyr::full_join(
    x = dplyr::select(.data = dplyr::mutate(.data = vs_tidy$data, VISIT = as.character(VISIT)), -DOMAIN),
    y = dplyr::select(.data = dplyr::mutate(.data = lb_tidy$data, VISIT = as.character(VISIT)), -DOMAIN),
    by = c("STUDYID", "SUBJID", "VISIT")
  ),
  by = c("STUDYID", "SUBJID", "VISIT")
) %>%
  dplyr::mutate(
    VISIT = factor(
      x = VISIT,
      levels = c(
        "BASELINE", 
        sort(grep("VISIT", unique(VISIT), value = TRUE)), 
        "LAST"
      )
    )
  ) %>% 
  dplyr::group_by(STUDYID, SUBJID) %>%
  dplyr::filter(
    (VISIT=="BASELINE" & !is.na(AGE) & !is.na(SEX)) | VISIT!="BASELINE"
  ) %>% 
  dplyr::arrange(VISIT) %>% 
  dplyr::mutate(
    AGE0 = AGE[1],
    BMI0 = BMI[1],
    SEX0 = as.numeric(SEX=="M")[1]
  ) %>% 
  as.data.frame()

if (exists("APMH") && "FAMILYID" %in% colnames(APMH)) {
  DMVSLB <- dplyr::left_join(
    x = DMVSLB,
    y = APMH %>% 
      dplyr::select(STUDYID, FAMILYID, SUBJID) %>% 
      dplyr::distinct(),
    by = c("STUDYID", "SUBJID")
  )
} else {
  DMVSLB <- dplyr::mutate(.data = DMVSLB, FAMILYID = SUBJID)
}

### To check if all individuals have the same number of visits before convert
DMVSLB <- dplyr::mutate(
  .data = DMVSLB,
  VISIT_YEARS = as.numeric(
    difftime(as.Date(VSDTC), min(as.Date(VSDTC), na.rm = TRUE), unit = "weeks") / 52.25
  )
)
```

## Make sure measured biomarker data are in the same units across all the cohorts

### Demographic variables

```{r display_demographic_marker_description, eval = params_steps$step_2}
pretty_kable(vs_tidy$annotation)
```

### Check if unit is the International Unit

```{r check_units_needs_convert, eval = params_steps$step_2}
lb_tidy$annotation <- lb_tidy$annotation %>%
  dplyr::mutate(
    CONVERT_TO =
      ifelse(
        tolower(LBORRESU)%in%c("g/l", "mg/l"),
        "mmol/l",
        ifelse(
          LBORRESU%in%"%" & LBTESTCD == "HBA1C",
          "mmol/mol",
          NA
        )
      )
  )
```

```{r display_biomarker_description, eval = params_steps$step_2}
tmp <- lb_tidy$annotation %>%
  dplyr::filter(grepl("GLUC", LBTESTCD) | grepl("HBA1C", LBTESTCD)) 
pretty_kable(tmp[, -c(ncol(tmp), ncol(tmp)-1)])
```

```{r display_biomarker_to_convert, eval = params_steps$step_2}
tmp <- lb_tidy$annotation %>%
  dplyr::filter(!is.na(CONVERT_TO)) %>%
  dplyr::filter(grepl("GLUC", LBTESTCD) | grepl("HBA1C", LBTESTCD)) %>% 
  dplyr::select(LBTEST, LBTESTCD)

if (nrow(tmp)==0) {
  "All variables are in the International unit."
} else {
  cat(
    paste0(
      "The following variables have been converted to International Units (mmol/l or mmol/mol):\n\n",
      paste0(
        "  * ",
        paste0(tmp[, "LBTEST"], " (`", tmp[, "LBTESTCD"], "`)"),
        collapse = "\n"
      )
    )
  )
}
cat("\n")
```

```{r convert_biomarker_units, eval = params_steps$step_2, include = FALSE}
variables_gl_to_convert <- dplyr::filter(
  .data = lb_tidy$annotation, !is.na(CONVERT_TO) & tolower(LBORRESU)%in%"g/l"
)[["KEY_MEASURES"]]

variables_mgl_to_convert <- dplyr::filter(
  .data = lb_tidy$annotation, !is.na(CONVERT_TO) & tolower(LBORRESU)%in%"mg/l"
)[["KEY_MEASURES"]]

variables_percent_to_convert <- dplyr::filter(
  .data = lb_tidy$annotation, !is.na(CONVERT_TO) & LBORRESU%in%"%"
)[["KEY_MEASURES"]]

DMVSLB <- DMVSLB %>%
  dplyr::mutate_at(
    .vars = dplyr::vars(!!!variables_gl_to_convert),
    .funs = dplyr::funs(convert_2mmoll(., from = "g/l"))
  ) %>%
  dplyr::mutate_at(
    .vars = dplyr::vars(!!!variables_mgl_to_convert),
    .funs = dplyr::funs(convert_2mmoll(., from = "mg/l"))
  ) %>%
  dplyr::mutate_at(
    .vars = dplyr::vars(variables_percent_to_convert),
    .funs = dplyr::funs(convert_hba1c(., unitFrom = "%"))
  )

varNamesGLUC <- grep("^GLUC.*_0$", colnames(DMVSLB), value = TRUE)
varNamesGLUC2H <- grep("^GLUC.*_120$", colnames(DMVSLB), value = TRUE)
varNamesHBA1C <- grep("^HBA1C.*$", colnames(DMVSLB), value = TRUE)

if (length(varNamesGLUC) == 0) {
  varNamesGLUC_new <- "GLUC_NA"
  DMVSLB[, varNamesGLUC_new] <- NA
} else {
  varNamesGLUC_new <- sapply(
    X = varNamesGLUC, 
    FUN = gsub, pattern = "(GLUC_.).*", replacement = "\\1"
  )
  DMVSLB[, varNamesGLUC_new] <- DMVSLB[, varNamesGLUC]
}

if (length(varNamesGLUC2H) == 0) {
  varNamesGLUC2H_new <- "GLUC2H_NA"
  DMVSLB[, varNamesGLUC2H_new] <- NA
} else {
  varNamesGLUC2H_new <- sapply(
    X = varNamesGLUC2H, 
    FUN = gsub, pattern = "(GLUC)(_.).*", replacement = "\\12H\\2"
  )
  DMVSLB[, varNamesGLUC2H_new] <- DMVSLB[, varNamesGLUC2H]
}

if (length(varNamesHBA1C) == 0) {
  varNamesHBA1C_new <- "HBA1C_NA"
  DMVSLB[, varNamesHBA1C_new] <- NA
} else {
  varNamesHBA1C_new <- sapply(
    X = varNamesHBA1C, 
    FUN = gsub, pattern = "(HBA1C_.).*", replacement = "\\1"
  )
  DMVSLB[, varNamesHBA1C_new] <- DMVSLB[, varNamesHBA1C]
}

variables_names <- c(varNamesGLUC_new, varNamesGLUC2H_new, varNamesHBA1C_new)

### Blood to Plasma measure conversion for ADDITION/MDC/etc cohort
if (sum(grepl("GLUC_", variables_names))==2) {
  cat(
    "`GLUC_B` (blood) measures have been converted to `GLUC_P` (plasma), 
    using $\text{GLUC_P} = 0.64 + 1.05 \times \text{GLUC_B})$\n"
  )
  cat("\n")
  DMVSLB <- DMVSLB %>% 
    dplyr::mutate(
      GLUC_P = ifelse(is.na(GLUC_P), 0.64 + 1.05 * GLUC_B, GLUC_P)
    )
  variables_names <- setdiff(variables_names, "GLUC_B")
}

if (sum(grepl("GLUC2H_", variables_names))==2) {
  cat(
    "`GLUC2H_B` (blood) measures have been converted to `GLUC2H_P` (plasma), 
    using $\text{GLUC2H_P} = -0.30 + 0.97 \times \text{GLUC2H_B})$\n"
  )
  cat("\n")
  DMVSLB <- DMVSLB %>% 
    dplyr::mutate(
      GLUC2H_P = ifelse(is.na(GLUC2H_P), -0.30 + 0.97 * GLUC2H_B, GLUC2H_P)
    )
  variables_names <- setdiff(variables_names, "GLUC2H_B")
}
```

## Keep only participants that are fasted at baseline

```{r fasted_samples, eval = params_steps$step_2}
if (all(is.na(DMVSLB[, "LBFAST"]))) {
  cat(
    "Fasting information (`LBFAST`) is not available: all individuals are kept and supposed to be fasted at baseline.  \n\n"
  )
  cat("\n")
  DMVSLB_QC0 <- DMVSLB
} else {
  non_fasted_samples <- DMVSLB %>%
    dplyr::group_by(STUDYID, SUBJID) %>%
    dplyr::filter(VISIT == "BASELINE") %>%
    dplyr::filter(!(LBFAST%in%"Y" | is.na(LBFAST))) %>%
    dplyr::select(STUDYID, SUBJID) %>%
    dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
    dplyr::ungroup() %>%
    .[["ID"]]

  DMVSLB_QC0 <- DMVSLB %>%
    dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
    dplyr::filter(!ID%in%non_fasted_samples) %>%
    dplyr::select(-ID)

  na_fasted_samples <- DMVSLB_QC0 %>%
    dplyr::group_by(STUDYID, SUBJID) %>%
    dplyr::filter(VISIT == "BASELINE" & is.na(LBFAST)) %>%
    dplyr::ungroup() %>%
    dplyr::count() %>%
    .[["n"]]

  cat(
    paste(
      "Fasting information (`LBFAST`) is missing for", 
      format(na_fasted_samples, big.mark = ","), 
      "individuals: these individuals are kept and supposed to be fasted at baseline.  \n\n"
    )
  )
  cat("\n")
}
```

Total individuals available : `r ifelse(params$analysis_step>=2, DMVSLB_QC0 %>% dplyr::select(STUDYID, SUBJID) %>% dplyr::distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

## Exclusion of participants with data available for only one time-point

```{r check_samples_with_one_measure, eval = params_steps$step_2}
variables_names_available <- variables_names[!grepl("_NA", variables_names)]

n_variables <- DMVSLB_QC0 %>%
  dplyr::group_by(STUDYID, SUBJID) %>%
  dplyr::summarise_at(
    .vars = dplyr::vars(!!variables_names_available),
    .funs = (function(.x) {sum(!is.na(.x))})
  ) 

one_measure_variables <- colSums(n_variables[, variables_names_available]<=1)==nrow(n_variables)
if (any(one_measure_variables)) {
  if (sum(one_measure_variables)>1) {
    message_cat <- "The following variables have been discarded (only one measure for all samples:\n"
  } else {
    message_cat <- "The following variable has been discarded (only one measure for all samples:\n"
  }
  cat(message_cat)
  cat(paste("  *", variables_names_available[one_measure_variables]), sep = "   \n")
  cat("\n")
}
variables_names_available <-  variables_names_available[!one_measure_variables]

one_time_point_samples <- n_variables %>%
  dplyr::filter_at(
    .vars = dplyr::vars(!!!variables_names_available),
    .vars_predicate = dplyr::all_vars(. <= 1)
  ) %>%
  dplyr::select(STUDYID, SUBJID) %>%
  dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  dplyr::ungroup() %>%
  .[["ID"]]

DMVSLB_QC1 <- DMVSLB_QC0 %>%
  dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  dplyr::filter(!ID%in%one_time_point_samples) %>%
  dplyr::select(-ID)
```

Total individuals available : `r ifelse(params$analysis_step>=2, DMVSLB_QC1 %>% dplyr::select(STUDYID, SUBJID) %>% dplyr::distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

## Exclusion of participants with diabetes at baseline

  * Fasting glucose $\geq$ 7.0 mmol/l (126 mg/dl; 1.26 g/l) => `GLUC`
  * 2–h glucose $\geq$ 11.1 mmol/l (200 mg/dl; 2 g/l) => `GLUC2H`
  * HbA1c $\geq$ 48 mmol/mol (6.5 %)  => `HBA1C`

```{r check_diabetic_baseline, eval = params_steps$step_2}
baseline_diabetes_samples <- DMVSLB_QC1 %>%
  dplyr::group_by(STUDYID, SUBJID) %>%
  dplyr::mutate_at(
    .vars = dplyr::vars(grep("GLUC_", variables_names, value = TRUE)), 
    .funs = ~.>=7.0
  ) %>% 
  dplyr::mutate_at(
    .vars = dplyr::vars(grep("HBA1C_", variables_names, value = TRUE)), 
    .funs = ~.>=48
  ) %>% 
  dplyr::filter(VISIT=="BASELINE") %>%
  dplyr::filter_at(
    .vars = dplyr::vars(
      grep("GLUC_", variables_names, value = TRUE), 
      grep("HBA1C_", variables_names, value = TRUE)
    ),
    .vars_predicate = dplyr::any_vars(.==TRUE)
  ) %>%
  dplyr::select(STUDYID, SUBJID) %>%
  dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  dplyr::ungroup() %>%
  .[["ID"]]

DMVSLB_QC2 <- DMVSLB_QC1 %>%
  dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  dplyr::filter(!ID%in%baseline_diabetes_samples) %>%
  dplyr::select(-ID)
```

Total individuals available : `r ifelse(params$analysis_step>=2, DMVSLB_QC2 %>% dplyr::select(STUDYID, SUBJID) %>% dplyr::distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

## Exclusion of participants developing diabetes during the study time without informations about medication

```{r check_incident_diabetic_medication, eval = params_steps$step_2}
# Get samples developing diabetes according to definition
follow_up_diabetes_samples_def <- DMVSLB_QC2 %>%
  dplyr::group_by(STUDYID, SUBJID) %>%
  dplyr::mutate_at(
    .vars = dplyr::vars(grep("GLUC_", variables_names, value = TRUE)), 
    .funs = ~.>=7.0
  ) %>% 
  dplyr::mutate_at(
    .vars = dplyr::vars(grep("HBA1C_", variables_names, value = TRUE)), 
    .funs = ~.>=48
  ) %>% 
  dplyr::filter_at(
    .vars = dplyr::vars(
      grep("GLUC_", variables_names, value = TRUE), 
      grep("HBA1C_", variables_names, value = TRUE)
    ),
    .vars_predicate = dplyr::any_vars(.==TRUE)
  ) %>% 
  dplyr::select(STUDYID, SUBJID) %>%
  dplyr::distinct() %>%
  dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  dplyr::ungroup() %>%
  .[["ID"]]

# Get samples diagnose diabetes during the follow-up
if (exists("MH")) {
  follow_up_diabetes_samples_diag <- MH %>%
    dplyr::filter(
      MHTERM%in%c("DIABETES", "TYPE 1 DIABETES", "TYPE 2 DIABETES") & MHOCCUR == "Y"
    ) %>%
    dplyr::select(STUDYID, SUBJID) %>%
    dplyr::distinct() %>%
    dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
    dplyr::ungroup() %>%
    .[["ID"]]
  
  incident_t2d_samples_list <- unique(c(follow_up_diabetes_samples_def, follow_up_diabetes_samples_diag))
} else {
  incident_t2d_samples_list <- unique(follow_up_diabetes_samples_def)
}

# Get medication information for all samples developing T2D based on definition and diagnostic
if (exists("CM")) {
  check_medication <- CM %>%
    dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
    dplyr::filter(ID %in% !!incident_t2d_samples_list) %>%
    dplyr::filter(
      CMCAT %in% c("INSULINS AND ANALOGUES", "BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS")
    ) %>%
    dplyr::group_by(ID, CMCAT) %>%
    dplyr::summarise(
      CHOCCUR = any(CMOCCUR%in%"Y")
    ) %>%
    dplyr::ungroup() %>%
    dplyr::filter(CHOCCUR)

  # List samples with 'INSULINS AND ANALOGUES' medication for later exclusion
  samples_with_insulin <- dplyr::filter(check_medication, CMCAT %in% "INSULINS AND ANALOGUES")[["ID"]]
  
  # List incident diabetic samples with 'BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS'
  # and without 'INSULINS AND ANALOGUES' medication
  diabetic_samples_with_medication_info <- setdiff(
    x = dplyr::filter(check_medication, CMCAT %in% "BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS")[["ID"]],
    y = samples_with_insulin
  )
} else {
  diabetic_samples_with_medication_info <- NULL
}

# List incident diabetic samples without medication information an/or 'INSULINS AND ANALOGUES'
FollowUpDiabetesSamples.ToExclude <- setdiff(
  x = incident_t2d_samples_list,
  y = diabetic_samples_with_medication_info
)

# Exclude samples in 'FollowUpDiabetesSamples.ToExclude'
DMVSLB_QC3 <- DMVSLB_QC2 %>%
  dplyr::mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  dplyr::filter(!ID %in% FollowUpDiabetesSamples.ToExclude) %>%
  dplyr::select(-ID)
```

Total individuals available after QC: `r ifelse(params$analysis_step>=2, DMVSLB_QC3 %>% dplyr::select(STUDYID, SUBJID) %>% dplyr::distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.


# Preliminary modelling

## Summary

The linear mixed model (LMM) is a suitably flexible approach, given that the intervals between data collection points is not uniform between cohorts; the LMM also permits the inclusion of different covariates, as well as unbalanced data within each cohort. 

The LMM can be described as $y_{ij}=\alpha+\alpha_i+\beta t_{ij}+\beta_i t_{ij}+\epsilon_{ij}$, where $y_{ij}$ is a trait measurement for participant $i$ at time $j$ ($j=1,2,\dots$), $\alpha$ and $\beta$ are fixed effects for average intercept and time (slope), respectively.  
$\alpha_i$ and $\beta_i$ are the individual (random) intercept and slope for participant $i$, assumed to be correlated and $\left(\alpha_i, \beta_i\right)\sim \mathcal{N}_2(0,\Sigma)$, *i.e.*, coming from two-dimensional normal distribution. 
$\epsilon_{ij}\sim \mathcal{N}(0,\sigma^2)$ is a random error term.  
Baseline time is set to zero; hence $t$ is the time since baseline.  
To adjust for different covariates (both time invariant and those varying over time) additional parameters can be added to the model.  
To account for the possibility that the baseline trait has an effect on subsequent measurements, one can introduce a binary variable: `1` when baseline measurement and `0` otherwise.

For cohorts with only two time-points, only a random intercept can be fitted; hence, the $\beta_i$ parameter is removed from the model and a random intercept is derived from a one-dimensional normal distribution ($\alpha_i\sim \mathcal{N}(0,\sigma_\alpha^2)$).

For cohorts containing family data, the correlation between family members has to be taken into account. 

Default covariates included in the model are `AGE0`, `SEX0` and `BMI0` (baseline values).  
Additional covariates might be needed depending on the cohort.


## First Run {.tabset}

```{r preliminary_first_run_check_number_measures, eval = params_steps$step_3}
nTimePoints <- max(table(DMVSLB_QC3[[ "SUBJID"]]))

# Include random slope if more than two time points
if (isTRUE(all.equal(DMVSLB_QC3[["FAMILYID"]], DMVSLB_QC3[["SUBJID"]]))) {
  random_term <- "SUBJID"
} else {
  random_term <- "SUBJID/FAMILYID"
}
if (nTimePoints > 2) {
  formula.rightPart <- as.formula(
    paste0(
      "~ 1 + AGE0 + SEX0 + BMI0 + VISIT_YEARS + (1 + VISIT_YEARS | ", random_term, ")"
    )
  )
  cat(
    paste0(
      "Random intercept and random slope are included in the model (up to ", 
      nTimePoints, 
      " time points available).\n\n"
    )
  )
  cat("\n")
} else {
  formula.rightPart <- as.formula(
    paste0(
      "~ 1 + AGE0 + SEX0 + BMI0 + VISIT_YEARS + (1 | ", random_term, ")"
    )
  )
  cat(
    paste0(
      "Only a random intercept is included in the model (up to ", 
      nTimePoints, 
      " time points available).\n\n"
    )
  )
  cat("\n")
}
```

```{r preliminary_first_run, eval = params_steps$step_3}
residuals_outliers <- as.list(rep_len(NA, length(variables_names)))
names(residuals_outliers) <- variables_names

for (ivariable in variables_names) {
  if (grepl("GLUC_", ivariable)) {
    big_names <- "Glucose"
  }
  if (grepl("GLUC2H_", ivariable)) {
    big_names <- "2-Hour glucose"
  }
  if (grepl("HBA1C_", ivariable)) {
    big_names <- "HbA1c"
  }
  
  cat(paste0("\n\n### ", big_names, " (`", ivariable, "`) {.tabset}\n"))

  fit_data <- dplyr::select(
    .data = DMVSLB_QC3, 
    dplyr::matches(ivariable), AGE0, SEX0, BMI0, VISIT_YEARS, FAMILYID, SUBJID, STUDYID
  )
  
  if (ivariable %in% variables_names_available) {
    fit <- lmerTest::lmer(
      formula = eval(parse(
        text = paste0("update.formula(formula.rightPart, ", ivariable, "~.)")
      )),
      data = fit_data
    )
    
    cat("\n#### Trajectories {-}\n\n")
    pTraj <- dplyr::mutate(
      .data = fit_data,
      ID = paste(STUDYID, SUBJID, sep = "_"),
      pT2D = ifelse(
        ID %in% diabetic_samples_with_medication_info,
        "Pre-Diabetes",
        "Normoglycaemia"
      )
    ) %>%
      ggplot2::ggplot(
        data = ., 
        mapping = ggplot2::aes_string(x = "VISIT_YEARS", y = ivariable, colour = "ID")
      ) +
        ggplot2::geom_line(na.rm = TRUE) +
        ggplot2::guides(colour = "none") +
        viridis::scale_colour_viridis(discrete = TRUE, begin = 0, end = 4 / 5) +
        ggplot2::facet_grid(.~pT2D)
    print(pTraj)
    cat("\n")
    
    
    cat("\n#### Residuals plot {-}\n\n")
    p0 <- cowplot::plot_grid(
      ggplot2::ggplot(
        data = data.frame(x = fitted(fit), y = residuals(fit)), 
        mapping = ggplot2::aes(x = x, y = y)
      ) +
        ggplot2::geom_point(shape = 21, colour = viridis::viridis_pal()(1)) +
        ggplot2::labs(x = "Fitted", y = "Residuals"),
      ggplot2::ggplot(
        data = data.frame(y = residuals(fit), x = "x"), 
        mapping = ggplot2::aes(x = x, y = y)
      ) +
        ggplot2::geom_boxplot(
          shape = 21,
          colour = viridis::viridis_pal(begin = 0.5, end = 0.5)(1),
          outlier.shape = 21
        ) +
        ggplot2::geom_hline(
          yintercept = median(residuals(fit)) + 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis::viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        ggplot2::geom_hline(
          yintercept = median(residuals(fit)) - 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis::viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        ggplot2::labs(y = "Residuals", x = NULL) +
        ggplot2::theme(axis.text.x = ggplot2::element_blank()),
      labels = LETTERS[c(1, 2)],
      align = "hv"
    )
    print(p0)
    cat("\n")
    
    
    residuals_outliers[[ivariable]] <- get_residuals_outliers(fit)
    
    
    cat("\n#### Random effect {-}\n\n")
    if (nTimePoints > 2) {
      # Compare model with or without random slope (anova)
      fit_random <- anova(
        eval(
          parse(
            text = paste0(
              "update(fit, formula = .~. - (1 + VISIT_YEARS | ", random_term, ") + (1 | ", random_term, "))"
            )
          )
        ),
        fit, refit = FALSE
      ) 
      fit_random <- as.data.frame(
        tibble::column_to_rownames(
          dplyr::mutate(.data = fit_random, Mod = c("Mod0", "Mod1")),
          var = "Mod"
        )
      )
      print(
        pretty_kable(
          data = fit_random, 
          pval_cols = grep("Pr(>Chisq)", colnames(fit_random), fixed = TRUE)
        )
      )
    } else {
      cat("Not enough time points to test a random slope term.")
      cat("\n")
    }
    
    
    cat("\n#### Fixed effect {-}\n\n")
    coeff_fit <- as.data.frame(coefficients(summary(fit)))
    
    if (any(grepl("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE))) {
      print(
        pretty_kable(
          data = coeff_fit, 
          pval_cols = grep("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE)
        )
      )
    } else {
      cat("Warning: p-values were not computed by lmerTest, probably due to computational error.")
      cat("\n")
    }
  } else {
    cat(paste0("`", ivariable, "` is not available."))
    cat("\n")
    residuals_outliers[[ivariable]] <- NULL
  }
}
```

## Second Run (after residuals check) {.tabset}

```{r preliminary_second_run_qc, eval = params_steps$step_3}
DMVSLB_QC4 <- DMVSLB_QC3 %>% 
  dplyr::filter(!SUBJID%in%unique(unlist(residuals_outliers)))
```

Total individuals available : `r ifelse(params$analysis_step>=3, DMVSLB_QC4 %>% dplyr::select(STUDYID, SUBJID) %>% dplyr::distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

```{r preliminary_second_run, eval = params_steps$step_3}
residuals_outliers <- as.list(rep_len(NA, length(variables_names)))
names(residuals_outliers) <- variables_names

for (ivariable in variables_names) {
  if (grepl("GLUC_", ivariable)) {
    big_names <- "Glucose"
  }
  if (grepl("GLUC2H_", ivariable)) {
    big_names <- "2-Hour glucose"
  }
  if (grepl("HBA1C_", ivariable)) {
    big_names <- "HbA1c"
  }
  
  cat(paste0("\n\n### ", big_names, " (`", ivariable, "`) {.tabset}\n"))

  fit_data <- dplyr::select(
    .data = DMVSLB_QC4, 
    dplyr::matches(ivariable), AGE0, SEX0, BMI0, VISIT_YEARS, FAMILYID, SUBJID, STUDYID
  )
  
  if (ivariable %in% variables_names_available) {
    fit <- lmerTest::lmer(
      formula = eval(parse(
        text = paste0("update.formula(formula.rightPart, ", ivariable, "~.)")
      )),
      data = fit_data
    )
    
    cat("\n#### Trajectories {-}\n\n")
    pTraj <- dplyr::mutate(
      .data = fit_data,
      ID = paste(STUDYID, SUBJID, sep = "_"),
      pT2D = ifelse(
        ID%in%diabetic_samples_with_medication_info,
        "PreDiab",
        "Normo"
      )
    ) %>%
      ggplot2::ggplot(
        data = ., 
        mapping = ggplot2::aes_string(x = "VISIT_YEARS", y = ivariable, colour = "ID")
      ) +
        ggplot2::geom_line(na.rm = TRUE) +
        ggplot2::guides(colour = "none") +
        viridis::scale_colour_viridis(discrete = TRUE, begin = 0, end = 4 / 5) +
        ggplot2::facet_grid(.~pT2D)
    print(pTraj)
    cat("\n")
    
    
    cat("\n#### Residuals plot {-}\n\n")
    p0 <- cowplot::plot_grid(
      ggplot2::ggplot(
        data = data.frame(x = fitted(fit), y = residuals(fit)), 
        mapping = ggplot2::aes(x = x, y = y)
      ) +
        ggplot2::geom_point(shape = 21, colour = viridis::viridis_pal()(1)) +
        ggplot2::labs(x = "Fitted", y = "Residuals"),
      ggplot2::ggplot(
        data = data.frame(y = residuals(fit), x = "x"), 
        mapping = ggplot2::aes(x = x, y = y)
      ) +
        ggplot2::geom_boxplot(
          shape = 21,
          colour = viridis::viridis_pal(begin = 0.5, end = 0.5)(1),
          outlier.shape = 21
        ) +
        ggplot2::geom_hline(
          yintercept = median(residuals(fit)) + 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis::viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        ggplot2::geom_hline(
          yintercept = median(residuals(fit)) - 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis::viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        ggplot2::labs(y = "Residuals", x = NULL) +
        ggplot2::theme(axis.text.x = ggplot2::element_blank()),
      labels = LETTERS[c(1, 2)],
      align = "hv"
    )
    print(p0)
    cat("\n")
    
    
    cat("\n#### Random effect {-}\n\n")
    if (nTimePoints > 2) {
      # Compare model with or without random slope (anova)
      fit_random <- anova(
        eval(
          parse(
            text = paste0(
              "update(fit, formula = .~. - (1 + VISIT_YEARS | ", random_term, ") + (1 | ", random_term, "))"
            )
          )
        ),
        fit, refit = FALSE
      )
      fit_random <- as.data.frame(
        tibble::column_to_rownames(
          dplyr::mutate(.data = fit_random, Mod = c("Mod0", "Mod1")),
          var = "Mod"
        )
      )

      print(
        pretty_kable(
          data = fit_random, 
          pval_cols = grep("Pr(>Chisq)", colnames(fit_random), fixed = TRUE)
        )
      )
    } else {
      cat("Not enough time points to test a random slope term.")
      cat("\n")
    }
    
    
    cat("\n#### Fixed effect {-}\n\n")
    coeff_fit <- as.data.frame(coefficients(summary(fit)))
    
    if (any(grepl("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE))) {
      print(
        pretty_kable(
          data = coeff_fit, 
          pval_cols = grep("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE)
        )
      )
    } else {
      cat("Warning: p-values were not computed by lmerTest, probably due to computational error.")
      cat("\n")
    }
  } else {
    cat(paste0("`", ivariable, "` is not available."))
    cat("\n")
    # residuals_outliers[[ivariable]] <- NULL
  }
}
```

# Descriptive statistics

```{r display_descriptive_statistics, eval = params_steps$step_3}
descriptive_table <- DMVSLB_QC4 %>%
  dplyr::group_by(STUDYID) %>%
  dplyr::mutate(
    NumberParticipants = format(length(unique(SUBJID)), big.mark = ","),
    MalesPercent = round((sum(SEX0) / length(SEX0)) * 100, digits = 2)
  ) %>%
  dplyr::group_by(STUDYID, SUBJID) %>%
  dplyr::mutate(
    NumberMeasures = length(unique(VISIT_YEARS)),
    FollowUpDuration = diff(range(VISIT_YEARS, na.rm = TRUE))
  ) %>%
  dplyr::filter(VISIT == "BASELINE") %>%
  dplyr::ungroup() %>%
  dplyr::group_by(STUDYID) %>%
  (function(.data) {
    dplyr::full_join(
      x = .data %>% 
        dplyr::summarise(
          `Number of Participants` = unique(NumberParticipants),
          `Number of Measures` = compute_mean_sd(NumberMeasures, digits = 2),
          `Follow-Up Duration` = compute_mean_sd(FollowUpDuration, digits = 2),
          `Males Percentage` = unique(MalesPercent),
          `Age (Baseline)`= compute_mean_sd(AGE0, digits = 2),
          `BMI (Baseline)` = compute_mean_sd(BMI0, digits = 2)
        ),
      y = .data %>% 
        dplyr::summarise_at(.vars = dplyr::vars(variables_names), .funs = compute_mean_sd) %>% 
        `colnames<-`(c(colnames(.)[1], paste0(colnames(.)[-1], " (Baseline)"))),
      by = "STUDYID"
    )
  }) %>%
  dplyr::ungroup() %>%
  dplyr::select(
    STUDYID,
    `Number of Participants`, `Number of Measures`, `Follow-Up Duration`, `Males Percentage`,
    `Age (Baseline)`, `BMI (Baseline)`, 
    dplyr::everything()
  ) %>%
  t() %>%
  `colnames<-`(.[1, ]) %>%
  as.data.frame()

pretty_kable(descriptive_table[-1, , drop = FALSE])
```


# Association and interaction analyses

## Summary

To perform GWAS analysis, SNP main effect and $SNP \times time$ interaction term are included to the preliminary model above; these parameters are average linear effect of time and SNP effect on the rate change ($SNP \times time$), respectively. 


## Check available VCF files

Please, provide VCF files in dosage format and check the availability of the imputation quality tag used (*e.g.*, `INFO`).

```{r check_available_vcf, eval = params_steps$step_4}
list_vcf_files <- list.files(path = params$vcf_input_directory, pattern = ".vcf.gz$")
cat(
  paste0(
    "The following VCF files (", 
    length(list_vcf_files), 
    ") are available within the directory path provided: \n\n",
    paste0("  * ", list_vcf_files, collapse = "\n")
  )
)
cat("\n")
```

## Prepare and format VCF files

```{r export_rmarkdown_parameters, eval = params_steps$step_4}
#### Export Rmarkdown parameters in system environment for bash use
Sys.setenv(projectName = params$cohort_name)
Sys.setenv(vcfin = params$vcf_input_directory)
Sys.setenv(vcfout = params$output_directory)
Sys.setenv(imputationQualityTag = params$imputation_quality_tag)
Sys.setenv(vcftoolsPath = params$vcftools_binary_path)
Sys.setenv(chunksize = params$chunk_size)

cat(
  paste(
    paste0("#!/bin/sh\n\n", "./handleVCF.sh"),
    params$cohort_name,
    params$output_directory,
    params$imputation_quality_tag,
    params$vcftools_binary_path,
    "\n\n"
  ),
  sep = "",
  file = paste0(params$output_directory, "/handleVCF_", params$cohort_name, ".sh")
)
```

```{r list_vcf, eval = params_steps$step_4}
#### Format and split VCF using bash and vcftools (needs to be installed)
#### List all VCFs path in a file
list_files <- list.files(
  path = params$vcf_input_directory, 
  pattern = ".*.vcf.gz$",
  full.names = TRUE
)
if (params$exclude_X) list_files <- list_files[!(grepl("X", list_files) | grepl("23", list_files))]
if (params$debug) list_files <- list_files[grepl("21", list_files) | grepl("22", list_files)]
cat(list_files, sep = "\n", file = paste0(params$output_directory, "/vcffilespath.txt"))
cat(unique(DMVSLB_QC4[["SUBJID"]]), sep = "\n", file = paste0(params$output_directory, "/sample_qced.txt"))
```

### Manually format VCFs

Shell script can be run from your output directory (`` `r params$output_directory` ``) using the generated command line file (`` `r paste0("handleVCF_", params$cohort_name, ".sh")` ``) and shell script (`./utils/handleVCF.sh`, must be located in `` `r params$output_directory` ``).

### Automatically format VCFs

```{sh format_vcf, eval = params_steps$step_5 & params$format_vcfs, echo = params_steps$step_5 & params$format_vcfs, results = "hide"}
## Description:
## When analysing the SNPs in R (lme4) the scripts crashes due to the amount of SNPs.
## We need to break down the data into smaller pieces.
## In this script we take one vcf file as input (ex chr1).
## Filter out bad SNPs and extact dosage, impute and frequency.
## Author: Thomas Sparsø


## the input arguments are a vcf file (must be gzipped, only one chr)
# projectName=$1
# vcfout=$2
# imputationQualityTag=$3
# vcftoolsPath=$4
# chunksize=1000


echo -e "\n"
echo "Name of Project: $projectName"
echo "Name of imputation quality tag (INFO/*): $imputationQualityTag"


# to format only on chromosome 22 vcfs: $vcfin/22*.vcf.gz
# find $vcfin/*.vcf.gz | while read vcf
cat $vcfout/vcffilespath.txt | while read vcf
do

  base=`basename $vcf`
  echo "name of inputFile: $base"

  ## directory for extraction from vcf (dosage, freq, etc). and for the small vcf files
  chrDir=`basename $vcf .vcf.gz`
  eVCF=$vcfout/$chrDir/extractVCF
  sVCF=$vcfout/$chrDir/smallVCF
  mkdir -p $eVCF
  mkdir -p $sVCF


  ## clean up before we start
  rm -f $eVCF/*
  rm -f $sVCF/*


  ############# step 1: Delete the obviuos problematic SNPs, indels, and rare SNPs
  echo -e "\n"
  echo "Reduce bad SNPs in $base ... (takes a while if many SNPs)"
  $vcftoolsPath/vcftools --gzvcf $vcf \
    --get-INFO $imputationQualityTag \
    --out $eVCF/tmp
  awk '{if($5<0.3) print $1"\t"$2}' $eVCF/tmp.INFO > $eVCF/delme
  $vcftoolsPath/vcftools --gzvcf $vcf \
    --keep  $vcfout/sample_qced.txt \
    --exclude-positions $eVCF/delme \
    --maf 0.01 \
    --remove-indels \
    --remove-filtered-all \
    --recode-INFO-all \
    --recode \
    --stdout | gzip -c > $eVCF/filtered.$base


  ############ step 2: Break down the vcf file into smaller files.
  ############ Make a header and attached the header to all Files
  gunzip -c $eVCF/filtered.$base | head -n 200 | awk '/^#/' > $sVCF/tmpHeader

  ## unzip vcf and keep all but header. Split the files into lines of 1000 and call them pre*
  gunzip -c $eVCF/filtered.$base | awk '!/^#/' | split - --lines=$chunksize $sVCF/pre

  ## loop through the pre*, add the header and zip the file. Save as "small_*.vcf.gz"
  find $sVCF/pre* | while read pathToFile;
  do
    file=`basename $pathToFile`
    cat $sVCF/tmpHeader $sVCF/$file | gzip -c > $sVCF/small_${file}.vcf.gz
  done


  ########### step 3: is DS available?
  ###maybe we should check if dosage is available for all cohorts before we make a script here.



  ########### step 4: Extract dosage, impute, freq from each od the small VCFs
  echo -e "\n"
  echo extract dosage, R2, freq...

  find $sVCF/small* | while read pathToFile
  do
    file=`basename $pathToFile .vcf.gz`

    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --extract-FORMAT-info DS \
      --stdout | gzip -c > $eVCF/$file.DS.gz
      
    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --get-INFO $imputationQualityTag \
      --out $eVCF/$file
      
    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --hardy \
      --out $eVCF/$file
      
    # $vcftoolsPath/vcftools --gzvcf $pathToFile \
    #   --missing-site \
    #   --out $eVCF/$file
      
    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --freq \
      --out $eVCF/$file
    sed -i s/"{ALLELE:FREQ}"/frq1"\t"frq2/ $eVCF/$file.frq
  done


  ########## step 5: clean up
  rm -f $eVCF/filtered.$base
  rm -f $sVCF/tmpHeader
  rm -f $sVCF/pre*
  rm -f $eVCF/delme
  rm -f $eVCF/tmp.INFO

done
```


## Run Mixed Model with imputed genotypes

### Trajectories

```{r lmm_genotypes_plot, eval = params_steps$step_6}
DMVSLB_QC5 <- dplyr::filter(
  .data = DMVSLB_QC4,
  SUBJID %in% (
    grep(
      pattern = "extractVCF",
      x = list.dirs(params$output_directory, full.names = TRUE),
      value = TRUE
    ) %>% 
      .[1] %>% 
      list.files(pattern = ".DS.gz$", full.names = TRUE) %>% 
      .[1] %>% 
      utils::read.table(header = TRUE, check.names = FALSE) %>% 
      colnames() %>% 
      .[-c(1, 2)]
  )
)

DMVSLB_QC5 %>%
  dplyr::select(!!unname(variables_names), AGE0, SEX0, BMI0, VISIT_YEARS, FAMILYID, SUBJID, STUDYID) %>% 
  tidyr::gather(key = "Trait", value = "Measure", -c(AGE0, SEX0, BMI0, VISIT_YEARS, FAMILYID, SUBJID, STUDYID)) %>% 
  dplyr::mutate(
    ID = paste(STUDYID, SUBJID, sep = "_"),
    pT2D = ifelse(
      ID%in%diabetic_samples_with_medication_info,
      "PreDiab",
      "Normo"
    )
  ) %>%
    ggplot2::ggplot(
      data = ., 
      mapping = ggplot2::aes_string(x = "VISIT_YEARS", y = "Measure", colour = "ID")
    ) +
      ggplot2::geom_line(na.rm = TRUE) +
      ggplot2::guides(colour = "none") +
      viridis::scale_colour_viridis(discrete = TRUE, begin = 0, end = 4 / 5) +
      ggplot2::facet_grid(Trait~pT2D, scales = "free_y") +
      ggplot2::labs(y = "Measure (SI)")

cat("\n")
```

### Descriptive statistics

```{r lmm_descriptive_statistics, eval = params_steps$step_6}
descriptive_table <- DMVSLB_QC5 %>%
  dplyr::group_by(STUDYID) %>%
  dplyr::mutate(
    NumberParticipants = format(length(unique(SUBJID)), big.mark = ","),
    MalesPercent = round((sum(SEX0) / length(SEX0)) * 100, digits = 2)
  ) %>%
  dplyr::group_by(STUDYID, SUBJID) %>%
  dplyr::mutate(
    NumberMeasures = length(unique(VISIT_YEARS)),
    FollowUpDuration = diff(range(VISIT_YEARS, na.rm = TRUE))
  ) %>%
  dplyr::filter(VISIT == "BASELINE") %>%
  dplyr::ungroup() %>%
  dplyr::group_by(STUDYID) %>%
  (function(.data) {
    dplyr::full_join(
      x = .data %>% 
        dplyr::summarise(
          `Number of Participants` = unique(NumberParticipants),
          `Number of Measures` = compute_mean_sd(NumberMeasures, digits = 2),
          `Follow-Up Duration` = compute_mean_sd(FollowUpDuration, digits = 2),
          `Males Percentage` = unique(MalesPercent),
          `Age (Baseline)`= compute_mean_sd(AGE0, digits = 2),
          `BMI (Baseline)` = compute_mean_sd(BMI0, digits = 2)
        ),
      y = .data %>% 
        dplyr::summarise_at(.vars = dplyr::vars(variables_names), .funs = compute_mean_sd) %>% 
        `colnames<-`(c(colnames(.)[1], paste0(colnames(.)[-1], " (Baseline)"))),
      by = "STUDYID"
    )
  }) %>%
  dplyr::ungroup() %>%
  dplyr::select(
    STUDYID,
    `Number of Participants`, `Number of Measures`, `Follow-Up Duration`, `Males Percentage`,
    `Age (Baseline)`, `BMI (Baseline)`, 
    dplyr::everything()
  ) %>%
  t() %>%
  `colnames<-`(.[1, ]) %>%
  as.data.frame()

pretty_kable(descriptive_table[-1, , drop = FALSE])
```

### Mixed Model results

```{r genomic_component, eval = params_steps$step_6 & params$variants_analysis}
if (!is.null(params$genomic_component)) {
  genomic_component <- read.csv(file = params$genomic_component, header = TRUE)
  colnames(genomic_component) <- c("SUBJID", sprintf("PC%02d", seq(ncol(genomic_component) - 1)))
  genomic_component[["SUBJID"]] <- as.character(genomic_component[["SUBJID"]])
  
  
  DMVSLB_QC5 <- DMVSLB_QC5 %>% 
    dplyr::mutate(SUBJID = as.character(SUBJID)) %>% 
    dplyr::left_join(
      y = genomic_component,
      by = "SUBJID"
    )
  formula.rightPart <- update.formula(formula.rightPart, ~ . + PC01 + PC02)
}
cat(
  "The following model is used for each trait:\n", 
  as.character(update.formula(formula.rightPart, ~ . + SNP * VISIT_YEARS))
)
cat("\n")
```

```{r lmm_genotypes, eval = params_steps$step_6 & params$variants_analysis}
variables_names <- variables_names[variables_names%in%variables_names_available]

list_chrom_directories <- grep(
  pattern = "extractVCF",
  x = list.dirs(params$output_directory, full.names = TRUE),
  value = TRUE
)
if (params$debug) list_chrom_directories <- list_chrom_directories[1]

for (ichrdirectory in list_chrom_directories) {
  message(ichrdirectory)

  # dir.create(gsub("extractVCF", "output_chunks_lmm", ichrdirectory), showWarnings = FALSE, mode = "0777")
  ichrfilename <- gsub(".*/(.*)/extractVCF", "\\1", ichrdirectory)
  output_lmm_directory <- paste0(params$output_directory, "/output_chunks_lmm/", ichrfilename)
  dir.create(output_lmm_directory, showWarnings = FALSE, recursive = TRUE, mode = "0777")

  ## Read imputed genotypes (dosage file)
  list_dosage_file <- list.files(path = ichrdirectory, pattern = ".DS.gz$", full.names = TRUE)
  if (params$debug) list_dosage_file <- list_dosage_file[1]
  
  ## Parallelise on chunks
  trash <- parallel::mclapply(
    X = list_dosage_file,
    mc.cores = params$n_cpu,
    mc.preschedule = FALSE,
    DMVSLB_QC5 = DMVSLB_QC5,
    output_lmm_directory = output_lmm_directory,
    variables_names = variables_names, 
    formula_right_part = formula.rightPart,
    FUN = function(idosagefile, DMVSLB_QC5, output_lmm_directory, variables_names, formula_right_part) {
      message(idosagefile)
      log_file <- paste0(output_lmm_directory, "/", gsub(".*/([^.]*).*", "\\1", idosagefile), ".log")
      if (file.exists(log_file)) {
        message(
          paste0(
            'Chunk "', basename(idosagefile), '" from "', ichrfilename, '" was already analysed.', "\n",
            'Chunk "', basename(idosagefile), " is skipped."
          )
        )
        return(NULL)
      }
      dosage_file <- utils::read.table(file = idosagefile, header = TRUE, check.names = FALSE)
  
      ## Check intersect between phenotypes and genotypes data
      samplesWithPhenoGeno <- intersect(
        unique(DMVSLB_QC5[["SUBJID"]]),
        colnames(dosage_file)[-c(1, 2)]
      )
  
      ## Format genotypes
      dosage_file_tidy <- dplyr::select(
        .data = dplyr::mutate(
          .data = dosage_file[, c("CHROM", "POS", samplesWithPhenoGeno)],
          SNP = paste(CHROM, POS, sep = "_")
        ),
        -CHROM, -POS
      )
      
      ## Remove multi-allele SNPs (duplicated chromosome:positition)
      multi_allele_snps <- dosage_file_tidy[duplicated(dosage_file_tidy[, "SNP"]), "SNP"]
      
      dosage_file_tidy <- as.data.frame(
        t(
          tibble::column_to_rownames(
            dplyr::filter(
              .data = as.data.frame(dosage_file_tidy), 
              !SNP%in%multi_allele_snps
            ),
            var = "SNP"
          )
        ) 
      )
  
      ## Combine phenotypes and genotypes
      pheno_geno_data <- dplyr::full_join(
        x = DMVSLB_QC5,
        y = dplyr::mutate(
          .data = tibble::rownames_to_column(dosage_file_tidy, var = "SUBJID"), 
          SUBJID = as.integer(SUBJID)
        ),
        by = "SUBJID"
      )
  
      ## Run Mixed Model by SNP
      results_lmm_snp <- lapply(
        X = colnames(dosage_file_tidy),
        mc_variables_names = variables_names,
        mc_pheno_geno_data = pheno_geno_data,
        mc_formula_right = formula_right_part,
        FUN = function(isnp, mc_variables_names, mc_pheno_geno_data, mc_formula_right) {
          try({
            purrr::map_df(.x = mc_variables_names, .f = function(ivariable) {
              local_formula <- eval(parse(text = paste0(
                "update.formula(mc_formula_right, ", ivariable, "~.+`", isnp, "`*VISIT_YEARS)"
              )))
              local_data <- mc_pheno_geno_data[, all.vars(local_formula)]
              if (!all(is.na(local_data[, ivariable]))) {
                fit_lmm <- lmerTest::lmer(formula = local_formula, data = local_data)
                out <- cbind.data.frame(
                  TRAIT = ivariable, 
                  SNP = isnp, 
                  N_TOTAL = length(unique(local_data[["SUBJID"]])),
                  tidy_lmer(fit_lmm), 
                  stringsAsFactors = FALSE
                )
                rownames(out) <- NULL
                colnames(out) <- gsub(
                  pattern = paste0("`", isnp, "`"),
                  replacement = "SNP",
                  x = colnames(out),
                  fixed = TRUE
                )
              } else {
                out <- data.frame(
                  TRAIT = ivariable, 
                  SNP = isnp, 
                  N_TOTAL = length(unique(local_data[["SUBJID"]])), 
                  stringsAsFactors = FALSE
                )
              }
              
              out
            })
          })
        }
      )
      list_errors <- sapply(results_lmm_snp, methods::is, class2 = "try-error")
  
      cat(
        colnames(dosage_file_tidy)[list_errors],
        sep = "\n",
        file = log_file
      )
      results_lmm_snp <- results_lmm_snp[!list_errors]
  
      annotation_chunk <- dplyr::full_join(
        x = dplyr::mutate(
          .data = readr::read_tsv(gsub(".DS.gz", ".frq", idosagefile)),
          POS = as.character(POS)
        ),
        y = dplyr::mutate(
          .data = readr::read_tsv(gsub(".DS.gz", ".hwe", idosagefile)),
          POS = as.character(POS)
        ), 
        by = c("CHROM" = "CHR", "POS" = "POS")
      )
      annotation_chunk <- dplyr::full_join(
        x = annotation_chunk,
        y = dplyr::mutate(
          .data = readr::read_tsv(gsub(".DS.gz", ".INFO", idosagefile)),
          POS = as.character(POS)
        ), 
        by = c("CHROM" = "CHROM", "POS" = "POS")
      ) %>%
        dplyr::mutate(SNP = paste(CHROM, POS, sep = "_"))
      
      # annotations_columns <- c(
      #   "SNP", "CHROM", "POS", "N_ALLELES", "N_CHR", "frq1", "frq2", 
      #   "OBS(HOM1/HET/HOM2)", "E(HOM1/HET/HOM2)", "ChiSq_HWE", "P_HWE", 
      #   "P_HET_DEFICIT", "P_HET_EXCESS", params$imputation_quality_tag, "TRAIT"
      # )
      
      results_lmm_chunk <- dplyr::full_join(
        x = annotation_chunk,
        y = dplyr::bind_rows(results_lmm_snp),
        by = "SNP"
      )
      
      results_lmm_chunk_output <- dplyr::rename(
        .data = results_lmm_chunk, 
        imputation_quality_INFO = !!params$imputation_quality_tag
      ) 
      cnames_output <- colnames(results_lmm_chunk_output)
      results_lmm_chunk_output <- dplyr::transmute(
        .data = results_lmm_chunk_output,
        TRAIT = TRAIT,
        SNPID = SNP,
        chr = as.integer(CHROM),
        position = as.integer(POS),
        coded_all = ALT,
        noncoded_all = REF,
        strand_genome = "+", # hardcoded strand, because when imputed, the forward strand is usually used
        beta = SNP_ESTIMATE,
        SE = SNP_SE,
        pval = SNP_PVALUE,
        beta_interaction = (
          if ("VISIT_YEARS:SNP_ESTIMATE" %in% cnames_output) {`VISIT_YEARS:SNP_ESTIMATE`} else {NA}
        ),
        SE_interaction = (
          if ("VISIT_YEARS:SNP_SE" %in% cnames_output) {`VISIT_YEARS:SNP_SE`} else {NA}
        ),
        pval_interaction = (
          if ("VISIT_YEARS:SNP_PVALUE" %in% cnames_output) {`VISIT_YEARS:SNP_PVALUE`} else {NA}
        ),
        AF_coded_all = frq2,
        HWE_pval = P_HWE, 
        # callrate = NA, 
        n_total = N_TOTAL, # N_CHR/N_ALLELES,
        # n_alleles = n_alleles,
        # imputed = as.numeric(imputation_quality_INFO!=1),
        # used_for_imp = as.numeric(imputation_quality_INFO==1),
        imputation_quality_INFO = imputation_quality_INFO
      )
  
      ## Write results
      trash <- lapply(X = variables_names, FUN = function(ivariable) {
        if (!grepl("_NA", ivariable)) {
          dir.create(paste0(output_lmm_directory, "/", ivariable), showWarnings = FALSE, mode = "0777")
          output_filename <- paste0(
            paste0(output_lmm_directory, "/", ivariable),
            "/", ivariable, "_",
            gsub(".*/([^.]*).*", "\\1", idosagefile),
            ".csv"
          )
          readr::write_csv(
            x = dplyr::filter(results_lmm_chunk_output, TRAIT == ivariable),
            path = output_filename,
            col_names = FALSE
          )
        }
      })
      # rm(
      #   list = c("results_lmm_chunk_output", "results_lmm_chunk", "annotation_chunk", "results_lmm_snp", "dosage_file")
      # )
    }
  )
  gc(verbose = FALSE, reset = TRUE)
}
```

```{r concatenate_chunks, eval = params_steps$step_6, include = params_steps$step_6}
csv_header <- paste0(params$output_directory, "/csv_header.csv")
readr::write_csv(
  x = cbind.data.frame(
    "TRAIT", "SNPID", "chr", "position", "coded_all", "noncoded_all", 
    "strand_genome", "beta", "SE", "pval", 
    "beta_interaction", "SE_interaction", "pval_interaction", 
    "AF_coded_all", "HWE_pval", "n_total", # "n_alleles", 
    "imputation_quality_INFO"
  ), 
  path = csv_header, 
  col_names = FALSE
)

dir.create(
  path = paste0(params$output_directory, "/results_to_send"), 
  recursive = TRUE, 
  showWarnings = FALSE, 
  mode = "0777"
)
concatenate_chunks <- dplyr::tibble(
  output_directory = params$output_directory,
  output_lmm = paste0(output_directory, "/output_chunks_lmm")
) %>% 
  dplyr::mutate(
    chr_directories = purrr::map(
      .x = output_lmm, 
      .f = list.dirs, 
      recursive = FALSE, 
      full.names = FALSE
    )
  ) %>% 
  tidyr::unnest(chr_directories) %>% 
  dplyr::mutate(
    trait_directories = purrr::map(
      .x = paste0(output_lmm, "/", chr_directories), 
      .f = list.dirs, 
      recursive = FALSE, 
      full.names = FALSE
    )
  ) %>% 
  tidyr::unnest(trait_directories) %>% 
  dplyr::mutate(
    chunk_file = purrr::map(
      .x = paste0(output_lmm, "/", chr_directories, "/", trait_directories), 
      .f = list.files, 
      full.names = FALSE
    )
  ) %>% 
  tidyr::unnest(chunk_file) %>% 
  dplyr::mutate(
    trait = trait_directories,
    chr = gsub("[^0-9]*([0-9]+)[^0-9]*", "\\1", chr_directories),
    chr = ifelse(!is.na(as.numeric(chr)), sprintf("%02d", as.numeric(chr)), chr),
    results_filename = paste0(output_directory, "/results_to_send/", params$cohort_name, "_", chr, "_", trait_directories, ".csv.gz")
  ) %>% 
  tidyr::unite(col = "file", c("output_lmm", "chr_directories", "trait_directories", "chunk_file"), sep = "/") %>% 
  dplyr::select(-output_directory) %>% 
  dplyr::group_by(trait, chr) %>% 
  tidyr::nest() %>% 
  dplyr::mutate(
    concatenate = purrr::map(.x = data, .f = function(.data) {
      cmd <- paste(
        "cat",
        paste(c(csv_header, sort(.data[["file"]])), collapse = " "),
        "| gzip >",
        unique(.data[["results_filename"]])
      )
      system(command = cmd, intern = TRUE)
    })
  )
unlink(csv_header)
```

```{r lmm_genotypes_ouput, eval = params_steps$step_6, include = params_steps$step_6}
concatenate_chunks %>% 
  tidyr::unnest(data) %>% 
  dplyr::slice(1) %>% 
  dplyr::select(results_filename) %>% 
  .[[1]] %>% 
  readr::read_csv(file = ., col_names = TRUE, n_max = 20) %>% 
  dplyr::mutate_at(.vars = dplyr::vars(dplyr::contains("PVALUE")), .funs = dplyr::funs(format_pval)) %>% 
  rmarkdown:::print.paged_df()
``` 


# Samples exclusion summary

```{r qc_summary, eval = params_steps$step_7}
count_samples <- function(data) { 
  nrow(dplyr::distinct(dplyr::select(.data = data, STUDYID, SUBJID)))
}

qc_steps <- dplyr::bind_rows(
  dplyr::tibble(
    `QC Step` = 1, 
    `QC Step Description` = "Exclude participants that are not fasted at baseline", 
    `Samples Before QC` = count_samples(DMVSLB),
    `Samples After QC` = count_samples(DMVSLB_QC0),
    `Samples Excluded` = `Samples Before QC`-`Samples After QC`
  ),
  dplyr::tibble(
    `QC Step` = 2, 
    `QC Step Description` = "Exclude participants with data available for one (or zero) time-point", 
    `Samples Before QC` = count_samples(DMVSLB_QC0),
    `Samples After QC` = count_samples(DMVSLB_QC1),
    `Samples Excluded` = `Samples Before QC`-`Samples After QC`
  ),
  dplyr::tibble(
    `QC Step` = 3, 
    `QC Step Description` = "Exclude participants with diabetes at baseline", 
    `Samples Before QC` = count_samples(DMVSLB_QC1),
    `Samples After QC` = count_samples(DMVSLB_QC2),
    `Samples Excluded` = `Samples Before QC`-`Samples After QC`
  ),
  dplyr::tibble(
    `QC Step` = 4, 
    `QC Step Description` = "Exclude participants developing diabetes during the study time without informations about medication", 
    `Samples Before QC` = count_samples(DMVSLB_QC2),
    `Samples After QC` = count_samples(DMVSLB_QC3),
    `Samples Excluded` = `Samples Before QC`-`Samples After QC`
  ),
  dplyr::tibble(
    `QC Step` = 5, 
    `QC Step Description` = "Exclude participants defined as outliers based on residuals from the mixed model, with median plus/minus 3*IQR", 
    `Samples Before QC` = count_samples(DMVSLB_QC3),
    `Samples After QC` = count_samples(DMVSLB_QC4),
    `Samples Excluded` = `Samples Before QC`-`Samples After QC`
  ),
  dplyr::tibble(
    `QC Step` = 6, 
    `QC Step Description` = "Exclude participants with no genotypes data available", 
    `Samples Before QC` = count_samples(DMVSLB_QC4),
    `Samples After QC` = count_samples(DMVSLB_QC5),
    `Samples Excluded` = `Samples Before QC`-`Samples After QC`
  )
) %>% 
  dplyr::mutate_if(.predicate = is.numeric, .f = ~format(x = .x, big.mark = ","))

pretty_kable(data = qc_steps)
```


# Output tree structure

```{r directory_structure, eval = params_steps$step_7, results = "markup"}
outout_tree_structure <- c(
  list.files(
    path = params$output_directory, 
    pattern = "[^0-9]*21[^0-9]*",
    full.names = TRUE
  ) %>%
    list.files(full.names = TRUE) %>%
    sapply(., list.files, pattern = "preaa", full.names = TRUE),
  list.files(
    path = params$output_directory, 
    pattern = "output_chunks_lmm", 
    full.names = TRUE
  ) %>%
    list.files(pattern = "21", full.names = TRUE) %>%
    list.files(full.names = TRUE) %>%
    gsub("small_pre.*.log", "small_pre*.log", .) %>% 
    unique() %>% 
    sapply(., function(i) {
      tmp <- list.files(i, pattern = "preaa", full.names = TRUE)
      ifelse(length(tmp) != 0, tmp, i)
    }) %>% 
    gsub("21", "CHR*", ., fixed = TRUE),
  list.files(
    path = params$output_directory, 
    pattern = "results_to_send", 
    full.names = TRUE
  ) %>%
    list.files(pattern = "21", full.names = TRUE),
  list.files(
    path = params$output_directory, 
    pattern = "vcffilespath.txt", 
    full.names = TRUE
  ),
  list.files(
    path = params$output_directory, 
    pattern = paste0("handleVCF_", params$cohort_name, ".sh"), 
    full.names = TRUE
  ),
  paste0(params$output_directory, "/RHAPSODY_WP3_PreDiab_", params$cohort_name, "_step", params$analysis_step, ".html")
) %>%
  unlist() %>%
  gsub(params$output_directory, paste0("/", params$cohort_name), .) %>%
  gsub("21", "CHR*", ., fixed = TRUE) %>%
  data.frame(pathString = .) %>%
  data.tree::as.Node()

cat(paste(sapply(utils::capture.output(outout_tree_structure)[-1], paste0, "\n"), collapse = ""))
```

```{r output_description, eval = params_steps$step_7}
output_description <- dplyr::tribble(
  ~"variable name", ~"description",
  "TRAIT", "trait used for the analysis (GLUC, GLUC2H or HBA1C)",
  "SNPID", "SNP ID as rs number",
  "chr", "chromosome number.",
  "position", "Chromosomal position relative to b37",
  "coded_all", "coded allele, also called modeled allele (in example of A/G SNP in which AA=0, AG=1 and GG=2, the coded allele is G)",
  "noncoded_all", "the alternate allele",
  "strand_genome", "'+' or '-', representing either the positive/forward strand or the negative/reverse strand of the human genome reference sequence; to clarify which strand the coded_all and noncoded_all are on",
  "beta", "beta estimate from genotype-phenotype association, at least 5 decimal places -- NA if not available",
  "SE", "standard error of beta estimate, to at least 5 decimal places -- NA if not available",
  "pval", "p-value of test statistic, here just as a double check -- NA if not available",
  "beta_interaction", "beta estimate from genotype-phenotype association in interaction with TIME, at least 5 decimal places -- NA if not available",
  "SE_interaction", "standard error of beta_interaction estimate, to at least 5 decimal places -- NA if not available",
  "pval_interaction", "p-value of test statistic, here just as a double check -- NA if not available",
  "AF_coded_all", "allele frequency for the coded allele -- NA if not available",
  "HWE_pval", "exact test Hardy-Weinberg equilibrium p-value -- only directly typed SNPs, NA for imputed",
  # "callrate", "genotyping call rate after exclusions -- only directly typed SNPs, NA for imputed",
  "n_total", "total sample with phenotype and genotype for SNP",
  # "n_alleles", "total number of alleles",
  # "imputed", "1/0 coding; 1=imputed SNP, 0=if directly typed",
  # "used_for_imp", "1/0 coding; 1=used for imputation, 0=not used for imputation",
  # "oevar_imp", "observed divided by expected variance for imputed allele dosage -- NA otherwise",
  "imputation_quality_INFO", "average posterior probability for imputed SNP allele dosage* (applies to best-guess genotype imputation) or R2"
)
pretty_kable(data = output_description)
```


# R session information

```{r session_info, results = "markup"}
devtools::session_info()
```

---
params:
  cohort_name: 'CohortName'
  author_name: 'Firstname LASTNAME'
  opal_credentials: 'opal_credentials.txt'
  vcf_input_directory: './vcfs'
  imputation_quality_tag: 'INFO'
  vcftools_binary_path: './vcftools/vcftools_latest/bin'
  output_directory: './'
  analysis_step: 1
  format_vcfs: TRUE
  variants_analysis: TRUE
  n_cpu: 2
  echo: FALSE
  warning: FALSE
  message: FALSE
title: 'RHAPSODY WP3 Pre-Diabetes Analysis Plan (Version 0.8.2)'
subtitle: '`r params$cohort_name`'
author: '`r params$author_name`'
date: '`r format(Sys.Date(), "%d %B %Y")`'
monofont: "Source Code Pro"
monofontoptions: "Scale=0.7"
output:
  html_document:
    keep_md: false
    theme: simplex
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
    fig_width: 5
    fig_height: 4
    number_sections: true
    self_contained: true
    mathjax: default
    df_print: kable
  pdf_document:
    toc: true
    toc_depth: 4
    fig_width: 6.3
    fig_height: 4.7
    number_sections: true
    df_print: kable
    keep_tex: true
    latex_engine: pdflatex
  word_document:
    toc: true
    toc_depth: 4
    fig_width: 6.3
    fig_height: 4.7
    df_print: kable
    keep_md: false
---

```{r setup, include = FALSE, echo = FALSE}
check_packages <- function(package) {
  if (!package %in% installed.packages()[, "Package"]) {
    install.packages(
			package, 
			repos = c(
			  "https://rhap-fdb01.vital-it.ch/repo/", 
			  "https://cran.rstudio.com/", 
			  "http://cran.obiba.org"
		  ),
			dependencies = TRUE
		)
  }
  library(package = package, character.only = TRUE)
}

list_packages <- c(
  "parallel",
  "grid",
  "scales",
  "broom",
  "viridis",
  "readxl",
  "writexl",
  "cowplot",
  "knitr",
  "kableExtra",
  "lme4",
  "lmerTest",
  "Hmisc",
  "data.tree",
  # "RCurl", 
  # "rjson",
  "opal",
  "tidyverse"
)

invisible(sapply(list_packages, check_packages))

check_steps <- function(params, max) {
  out <- as.list(rep(FALSE, 7))
  names(out) <- paste0("step_", seq_len(7))
  out[paste0("step_", seq_len(params$analysis_step))] <- TRUE
  return(out)
}
params_steps <- check_steps(params)

opts_chunk$set(
  cache = FALSE,
  echo = params$echo,
  warning = params$warning,
  error = TRUE,
  message = params$message,
  include = TRUE,
  tidy = FALSE,
  crop = TRUE,
  autodep = TRUE,
  fig.align = "center",
  fig.pos = "!H",
  dpi = 120,
  size = "small", 
  results = "asis"
)

# Code to resize font size of R code chunks output according to 'size' option (only LATEX)
if (knitr:::is_latex_output()) {
  def.chunk.hook <- knitr::knit_hooks$get("chunk")
  knitr::knit_hooks$set(chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(
      options$size != "normalsize", 
      paste0("\\", options$size, "\n\n", x, "\n\n \\normalsize"), 
      x
    )
  })
}
```

```{r check_parameters, echo = FALSE}
if (!file.exists(params$opal_credentials)) {
  stop(paste0('File "', params$opal_credentials, '" doesn\'t exist!\nPlease check the settings.'))
}
if (!file.exists(paste0(params$vcftools_binary_path, "/vcftools"))) {
  stop(paste0('Please check the path to vcftools: "', params$vcftools_binary_path, '" seems to be incorrect.'))
}
```

```{r define_r_functions, include = FALSE, echo = FALSE}
theme_set(theme_light(base_size = 12))

format_pval <- function (x, thresh = 10^-2, digits = 3, eps = 1e-50) {
  pout <- ifelse(
    x>=thresh, 
    Hmisc::format.pval(x, digits = digits, eps = eps, nsmall = digits), 
    base::format.pval(x, digits = digits, eps = eps, scientific = TRUE, nsmall = digits)
  )
  return(pout)
}

mykable <- function(
  data,
  font_size = 12,
  format.args = list(scientific = -1, digits = 3, big.mark = ","),
  col.names = NA,
  pval_cols = NULL,
  ...
) {
  if (!is.null(pval_cols)) {
    data[, pval_cols] <- format_pval(
      x = data[, pval_cols],
      digits = format.args$digits
    )
  }
  colnames(data) <- capitalize(colnames(data))
  if (knitr:::is_latex_output()) {
    options(knitr.table.format = "latex")
    kable(x = data, booktabs = TRUE, format.args = format.args, col.names = col.names, ...) %>%
      kable_styling(
        latex_options = c("hold_position"),
        full_width = FALSE,
        position = "center",
        font_size = font_size
      )
  } else {
    options(knitr.table.format = "html")
    kable(x = data, format.args = format.args, col.names = col.names, ...) %>%
      kable_styling(
        bootstrap_options = c("striped", "hover", "condensed", "responsive"),
        full_width = TRUE,
        position = "center",
        font_size = font_size
      )
  }
}

# reference table to convert HbA1c from percentage to mmol/mol
convertHbA1c <- function(x, unitFrom = "%") {
  if (unitFrom == "%") {
    HBA1Cconvert <- structure(list(
      V1 = c(
        10L, 12L, 14L, 16L, 18L, 20L, 22L, 24L,
        26L, 28L, 30L, 32L, 34L, 36L, 38L, 40L, 42L, 44L, 46L, 48L, 50L,
        52L, 54L, 56L, 58L, 60L, 62L, 64L, 66L, 68L, 70L, 72L, 74L, 76L,
        78L, 80L, 82L, 84L, 86L, 88L, 90L, 92L, 94L, 96L, 98L, 100L,
        102L, 104L, 106L, 108L, 110L, 112L, 114L, 116L, 118L, 120L, 122L,
        124L, 126L, 128L, 130L, 132L, 134L, 136L, 138L, 140L, 142L, 144L,
        146L, 148L, 150L, 152L, 154L, 156L, 158L, 160L, 162L, 164L, 166L,
        168L, 170L, 172L, 174L, 176L, 178L, 180L, 182L, 184L, 186L, 188L,
        190L, 192L, 194L, 196L, 198L, 200L, 202L, 204L, 208L, 210L
      ),
      V2 = c(
        3.1, 3.2, 3.4, 3.6, 3.8, 4, 4.2, 4.3, 4.5, 4.7, 4.9,
        5.1, 5.3, 5.4, 5.6, 5.8, 6, 6.2, 6.4, 6.5, 6.7, 6.9, 7.1,
        7.3, 7.5, 7.6, 7.8, 8, 8.2, 8.4, 8.6, 8.7, 8.9, 9.1, 9.3,
        9.5, 9.7, 9.8, 10, 10.2, 10.4, 10.6, 10.8, 10.9, 11.1, 11.3,
        11.5, 11.7, 11.8, 12, 12.2, 12.4, 12.6, 12.8, 12.9, 13.1,
        13.3, 13.5, 13.7, 13.9, 14, 14.2, 14.4, 14.6, 14.8, 15, 15.1,
        15.3, 15.5, 15.7, 15.9, 16.1, 16.2, 16.4, 16.6, 16.8, 17,
        17.2, 17.3, 17.5, 17.7, 17.9, 18.1, 18.3, 18.4, 18.6, 18.8,
        19, 19.2, 19.4, 19.5, 19.7, 19.9, 20.1, 20.3, 20.4, 20.6,
        20.8, 21, 21.2
      )
    ), .Names = c("V1", "V2"), class = "data.frame", row.names = c(NA, -100L))
    return(sapply(x, function(y) {
      round(sum(tidy(lm(V1~V2, data = HBA1Cconvert))[, "estimate"] * c(1, y)))
    }))
  } else {
    return(x)
  }
}

# function to convert g/l to mmol/l
convert2mmolL <- function(x, from = "g/l") {
  switch(EXPR = from,
    "g/l" = {
      x / 0.18
    },
    "g/L" = {
      x / 0.18
    },
    "mg/l" = {
      x / 0.18 / 100
    },
    "mg/L" = {
      x / 0.18 / 100
    },
    "mmol/l" = {
      x
    },
    "mmol/L" = {
      x
    }, {
      stop("Please check Units: g/l, g/L, mg/l or mg/L !")
    }
  )
}

# function to convert "Vital Signs" (VS) OPAL table (CDISC) to "long format"
formatTableVS <- function(data) {
  data <- data %>%
    mutate(
      KeyFactor = paste(DOMAIN, STUDYID, SUBJID, VISIT, sep = "_")
    ) %>%
    `rownames<-`(NULL)
  
  CovDesc <- data %>%
    select(c(DOMAIN, STUDYID, VSORRESU, VSTEST, VSTESTCD)) %>%
    distinct()
  
  if (!"VSTPTNUM"%in%colnames(data)) {
    data <- data %>% 
      mutate(VSTPTNUM = NA)
  }
  if (!"VSTPT"%in%colnames(data)) {
    data <- data %>% 
      mutate(VSTPT = NA)
  }
  
  data0 <- full_join(
    x = full_join(
      x = data %>%
        subset(is.na(VSTPTNUM)) %>%
        select(KeyFactor, VSORRES, VSTESTCD) %>%
        spread(key = "VSTESTCD", value = "VSORRES"),
      y = data %>%
        subset(!is.na(VSTPTNUM)) %>%
        select(KeyFactor, VSORRES, VSTESTCD, VSTPTNUM) %>%
        mutate(KeyMeasures = paste(VSTESTCD, VSTPTNUM, sep = "_")) %>%
        select(KeyFactor, KeyMeasures, VSORRES) %>%
        spread(key = "KeyMeasures", value = "VSORRES"),
      by = c("KeyFactor" = "KeyFactor")
    ),
    y = (data %>%
           select(-c(VSORRES, VSTPT, VSTPTNUM, VSORRESU, VSTEST, VSTESTCD)) %>%
           distinct()),
    by = c("KeyFactor" = "KeyFactor")
  ) %>%
    mutate(
      VISIT = factor(
        VISIT,
        levels = c("BASELINE", sort(grep("VISIT", unique(VISIT), value = TRUE)), "LAST")
      )
    ) %>%
    group_by(DOMAIN, STUDYID, SUBJID) %>%
    arrange(VISIT) %>%
    select(-KeyFactor) %>%
    data.frame()
  return(list(data = data0, annot = CovDesc))
}

# function to convert "Laboratory Measurements" (LB) OPAL table (CDISC) to "long format"
formatTableLB <- function(data) {
  data <- data %>%
    mutate(
      LBFAST = if ("LBFAST" %in% colnames(.)) {
        LBFAST
      } else {
        NA
      },
      LBTPTNUM = if ("LBTPTNUM" %in% colnames(.)) {
        LBTPTNUM
      } else {
        NA
      },
      LBTPTNUM = ifelse(LBTESTCD == "GLUC" & is.na(LBTPTNUM), 0, LBTPTNUM),
      KeyFactor = paste(DOMAIN, STUDYID, SUBJID, VISIT, sep = "_")
    ) %>%
    `rownames<-`(NULL)

  descVariables <- c("LBORRESU", "LBTEST", "LBTESTCD", "LBSPEC", "LBCAT", "LBMETHOD", "LBTPT", "LBTPTNUM", "AGCAT")
  CovDesc <- data %>%
    select(intersect(c("DOMAIN", "STUDYID", descVariables), colnames(.))) %>%
    distinct() %>%
    mutate(
      KeyMeasures = paste(LBTESTCD, LBSPEC, LBCAT, LBTPTNUM, sep = "_")
    )

  data0 <- full_join(
    x = (data %>%
      select(KeyFactor, LBORRES, LBTESTCD, LBSPEC, LBCAT, LBTPTNUM) %>%
      mutate(
        KeyMeasures = paste(LBTESTCD, LBSPEC, LBCAT, LBTPTNUM, sep = "_")
      ) %>%
      select(KeyFactor, KeyMeasures, LBORRES) %>%
      spread(key = "KeyMeasures", value = "LBORRES")),
    y = (data %>%
      select(c("LBDTC", "SUBJID", "VISIT", "DOMAIN", "STUDYID", "LBFAST", "KeyFactor")) %>%
      distinct()),
    by = c("KeyFactor" = "KeyFactor")
  ) %>%
    mutate(
      VISIT = factor(
        VISIT,
        levels = c("BASELINE", sort(grep("VISIT", unique(VISIT), value = TRUE)), "LAST")
      )
    ) %>%
    group_by(DOMAIN, STUDYID, SUBJID) %>%
    arrange(VISIT) %>%
    select(-KeyFactor) %>%
    data.frame()

  return(list(data = data0, annot = CovDesc))
}

compute_BMI <- function(data) {
  if (!"BMI"%in%data$annot[["VSTESTCD"]]) {
    weight_unit <- data$annot %>% 
      filter(VSTESTCD=="WEIGHT") %>% 
      select(VSORRESU) %>% 
      unlist()
    convert_weight_unit <- switch(
      EXPR = weight_unit,
      "kg" = {function(x) {x}},
      "lb" = {function(x) {x*0.45359237}}
    )
    
    height_unit <- data$annot %>% 
      filter(VSTESTCD=="HEIGHT") %>% 
      select(VSORRESU) %>% 
      unlist()
    convert_height_unit <- switch(
      EXPR = height_unit,
      "cm" = {function(x) {x/100}},
      "m" = {function(x) {x}},
      "in" = {function(x) {(x*2.54)/100}}
    )
    
    data$data <- data$data %>% 
      mutate(
        BMI = convert_weight_unit(WEIGHT) / convert_height_unit(HEIGHT)
      )
    default_CDISC_BMI <- structure(
      list(
        DOMAIN = "VS", 
        STUDYID = unique(data$annot[["STUDYID"]]), 
        VSORRESU = "kg/m2", 
        VSTEST = "Body Mass Index", 
        VSTESTCD = "BMI"
      ), 
      .Names = c("DOMAIN",  "STUDYID", "VSORRESU", "VSTEST", "VSTESTCD"), 
      row.names = 1L, 
      class = "data.frame"
    )
    data$annot <- bind_rows(data$annot, default_CDISC_BMI)
  }
  return(data)
}
```

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

# Goal

Combining two-point and multi-point longitudinal data from prediabetes cohorts to estimate the effects of genetic biomarkers on glycaemic trait rate change

## Key question to answer

Do genetic variants show association with the trait rate change?

## Summary

This analysis plan details the data preparation and analyses steps for detecting SNP associations with quantitative trait rate change (determined by modelling time x single nucleotide polymorphism (SNP) interactions) in RHAPSODY (Prediabetes cohorts within WP3: MDC, BOTNIA, ADDITION-PRO, DESIR, CoLAUS).

For  each genetic variant, we will seek to estimate the average linear effect of a given SNP over time (SNP effect) and SNP effect on the rate change (SNPxtime); thus, we will address the question of whether a given SNP is associated with the linear trajectory of the trait from baseline through follow-up. Non-linear trajectories may exist but because the available data is relatively sparse, we will not seek to model non-linear patterns. 

We will focus on the following glycaemic traits as outcomes: fasting glucose (FG), 2h glucose (2hG) and HbA1c. 

Results from analyses from different cohorts will be combined in two meta-analyses: one including all cohorts with data available from at least two time-points, and the second including only those cohorts with data available for at least three time-points. 

The latter analysis will yield a more precise estimation of longitudinal trajectories than when data from only two time-points are available. 

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

# R commands to run the Rmarkdown script
```{r run_analysis, eval = FALSE, echo = TRUE}
working_directory <- "./"

reportName <- "RHAPSODY_WP3_PreDiab_v0.5.9"
 
rmarkdown::render(
  input = "RHAPSODY_WP3_PreDiab.Rmd",
  output_format = "html_document",
  output_file = paste0(reportName, ".html"),
  output_dir = working_directory,
  params = list(
    cohort_name = 'CohortName',
    author_name = 'Firstname LASTNAME',
    opal_credentials = 'opal_credentials.txt',
    vcf_input_directory = './vcfs',
    imputation_quality_tag = 'INFO', # To be set according to VCF (could also be "R2")
    vcftools_binary_path = './vcftools/vcftools_latest/bin',
    output_directory = working_directory,
    analysis_step = 1,
    format_vcfs = FALSE,
    variants_analysis = FALSE,
    echo = FALSE, # Should R code be printed in the report
    warning = TRUE, # Should warnings be printed in the report
    message = TRUE # Should messages be printed in the report
  ),
  encoding = "UTF-8"
)
```

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

# R session information
Please use `r R.version.string` (if not possible, newer version "3.4.*" can be used).
```{r session_info, results = "markup"}
sessionInfo()
```

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

```{r open_opal_connection, eval = params_steps$step_1, results = ifelse(params$echo, "asis", "hide")}
cat("\n# Load data from OPAL node\n\n")
cat("\n## Open connection to OPAL node\n\n")

opal_credentials <- as.data.frame(t(read.table(
  file = params$opal_credentials, 
  stringsAsFactors = FALSE, 
  row.names = c("opal_server", "opal_login", "opal_password")
)), stringsAsFactors = FALSE)

o <- opal.login(
  username = opal_credentials$opal_login,
  password = opal_credentials$opal_password,
  url = opal_credentials$opal_server
)

cat("\n## Import table from OPAL node to local R session\n\n")
availableTable <- opal.datasources(opal = o)[[1]]$table

# Available tables in OPAL (Check RHAPSODY/CDISC documentation for details)
whichTable <- c("DM", "VS", "LB", "MH", "CM")

for (itable in whichTable) {
  opal.assign(opal = o, symbol = itable, value = paste0("rhapsody.", itable))
  assign(x = itable, value = opal.execute(o, itable))
}

cat("\n## Close connection to OPAL node and clean workspace\n\n")
opal.logout(o)
rm(list = c("o", "itable", "whichTable"))

cat("\n## Convert CDSIC to long format\n\n")
VSformat <- formatTableVS(data = VS)
LBformat <- formatTableLB(data = LB)
# To check if LB/VS are correctly formatted (should return TRUE)
# all(
#   nrow(LBformat$data) == length(unique(LB[["SUBJID"]]))*length(unique(LB[["VISIT"]])),
#   nrow(VSformat$data) == length(unique(VS[["SUBJID"]]))*length(unique(VS[["VISIT"]])),
#   nrow(LBformat$data) == nrow(VSformat$data)
# )

DMVSLB <- merge(
  x = DM %>% mutate(VISIT = "BASELINE") %>% select(-DOMAIN),
  y = merge(
    VSformat$data %>% select(-DOMAIN),
    LBformat$data %>% select(-DOMAIN),
    by = c("STUDYID", "SUBJID", "VISIT"),
    all = TRUE
  ),
  by = c("STUDYID", "SUBJID", "VISIT"),
  all = TRUE
) %>%
  group_by(STUDYID, SUBJID) %>%
  filter(
    (VISIT=="BASELINE" & !is.na(AGE) & !is.na(SEX)) |
      VISIT!="BASELINE"
  ) %>% 
  mutate(
    AGE0 = AGE[1],
    BMI0 = BMI[1],
    SEX0 = as.numeric(SEX=="M")[1]
  ) %>% 
  as.data.frame()


### To check if all individuals have the same number of visits before convert
if (
  DMVSLB %>%
    group_by(SUBJID) %>%
    summarise(n = length(SUBJID)) %>%
    select(n) %>%
    all()
) {
  DMVSLB <- DMVSLB %>%
    mutate(
      VISIT_YEARS = as.numeric(
        difftime(as.Date(VSDTC), min(as.Date(VSDTC), na.rm = TRUE), unit = "weeks") / 52.25
      )
    )
} else {
  cat("The number of visits per individuals differs!")
  cat("\n")
}
```

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

# Quality control of phenotype data

## Summary
1.  Make sure measured biomarker data are in the same units across all the cohorts.  
Fasting and 2-h plasma glucose in mmol/l and HbA1c in mmol/mol.
2.  For fasting and 2-h glucose, ensure only those participants who are fasted for at least 8-h are included.
3.  Exclusion of participants with data available from only one time-point.  
Only individuals with at least 2 observations should be included in the analysis.
4.  Exclusion of participants with diabetes at baseline.  
As we will focus on prediabetes (and also include participants with normoglycemia), prevalent cases of diabetes at baseline using ADA diagnostic criteria must be excluded; this applies to participants with known diabetes as well as those with screen-detected diabetes at baseline.  
Diagnostic criteria for diabetes ([ADA criteria; Diabetes Care 2015 Jan; 38, Supplement 1](http://care.diabetesjournals.org/content/suppl/2014/12/23/38.Supplement_1.DC1/January_Supplement_Combined_Final.6-99.pdf)):
    * Fasting plasma glucose $\geq$ 7.0 mmol/l (126 mg/dl) or
    * 2h plasma glucose $\geq$ 11.1 mmol/l (200 mg/dl) or
    * HbA1c $\geq$ 48 mmol/mol (6.5%). 
5.  Exclusion of participants developing diabetes during the study time:
    * Individuals developing diabetes during the follow up and with no available information on medication  should be excluded.
    * Individuals with Type I Diabetes or/and INSULIN and ANALOGUES treatment.
6.  Additional exclusion based on model diagnostics (see preliminary modelling for details)


`r if (knitr:::is_latex_output()) {'\\clearpage'}`

## Code results

### Make sure measured biomarker data are in the same units across all the cohorts

#### Demographic variables
```{r display_demographic_marker_description, eval = params_steps$step_2}
mykable(VSformat$annot)
```

#### Check if unit is the International Unit
```{r check_units_needs_convert, eval = params_steps$step_2}
LBformat$annot <- LBformat$annot %>%
  mutate(
    ConvertTo =
      ifelse(
        LBORRESU %in% c("g/l", "g/L", "mg/l", "mg/L"),
        "mmol/l",
        ifelse(
          LBORRESU %in% "%" & LBTESTCD == "HBA1C",
          "mmol/l",
          NA
        )
      )
  )
```

```{r display_biomarker_to_convert, eval = params_steps$step_2}
cat(
  paste0(
    "The following variables have been converted to mmol/l:\n\n",
    paste0(
      "  * ",
      LBformat$annot %>%
        filter(!is.na(ConvertTo)) %>%
        select(LBTEST, LBTESTCD) %>%
        (function(.data) {
          paste0(.data[, "LBTEST"], " (`", .data[, "LBTESTCD"], "`)")
        }),
      collapse = "\n"
    )
  )
)
cat("\n")
```

#### Display biomarkers and units
```{r display_biomarker_description, eval = params_steps$step_2}
mykable(LBformat$annot[, -c(ncol(LBformat$annot), ncol(LBformat$annot)-1)])
```

```{r convert_biomarker_units, eval = params_steps$step_2, include = FALSE}
DMVSLB <- DMVSLB %>%
  mutate_at(
    vars(
      LBformat$annot %>%
        filter(!is.na(ConvertTo) & LBORRESU %in% c("g/l", "g/L")) %>%
        select(KeyMeasures) %>%
        unlist()
    ),
    funs(convert2mmolL(., from = "g/l"))
  ) %>%
  mutate_at(
    vars(
      LBformat$annot %>%
        filter(!is.na(ConvertTo) & LBORRESU %in% c("mg/l", "mg/L")) %>%
        select(KeyMeasures) %>%
        unlist()
    ),
    funs(convert2mmolL(., from = "mg/l"))
  ) %>%
  mutate_at(
    vars(
      LBformat$annot %>%
        filter(!is.na(ConvertTo) & LBORRESU %in% c("%")) %>%
        select(KeyMeasures) %>%
        unlist()
    ),
    funs(convertHbA1c(., unitFrom = "%"))
  )

varNamesGLUC <- grep("^GLUC.*_0$", colnames(DMVSLB), value = TRUE)
varNamesGLUC2H <- grep("^GLUC.*_120$", colnames(DMVSLB), value = TRUE)
varNamesHBA1C <- grep("^HBA1C.*$", colnames(DMVSLB), value = TRUE)

if (length(varNamesGLUC) == 0) {
  varNamesGLUC_new <- "GLUC_NA"
  DMVSLB[, varNamesGLUC_new] <- NA
} else {
  varNamesGLUC_new <- sapply(varNamesGLUC, gsub, pattern = "(GLUC_.).*", replacement = "\\1")
  DMVSLB[, varNamesGLUC_new] <- DMVSLB[, varNamesGLUC]
}

if (length(varNamesGLUC2H) == 0) {
  varNamesGLUC2H_new <- "GLUC2H_NA"
  DMVSLB[, varNamesGLUC2H_new] <- NA
} else {
  varNamesGLUC2H_new <- sapply(varNamesGLUC2H, gsub, pattern = "(GLUC)(_.).*", replacement = "\\12H\\2")
  DMVSLB[, varNamesGLUC2H_new] <- DMVSLB[, varNamesGLUC2H]
}

if (length(varNamesHBA1C) == 0) {
  varNamesHBA1C_new <- "HBA1C_NA"
  DMVSLB[, varNamesHBA1C_new] <- NA
} else {
  varNamesHBA1C_new <- sapply(varNamesHBA1C, gsub, pattern = "(HBA1C_.).*", replacement = "\\1")
  DMVSLB[, varNamesHBA1C_new] <- DMVSLB[, varNamesHBA1C]
}

variables_names <- c(varNamesGLUC_new, varNamesGLUC2H_new, varNamesHBA1C_new)

### Blood to Plasma measure conversion for ADDITION cohort
if (params$cohort_name == "ADDITION") {
  convert_blood_to_plasma <- function(data) {
    data %>% 
      mutate(
        GLUC_P = ifelse(VISIT=="BASELINE", 0.64 + 1.05 * GLUC_B, GLUC_P),
        GLUC2H_P = ifelse(VISIT=="BASELINE", -0.30 + 0.97 * GLUC2H_B, GLUC2H_P)
      ) %>% 
      return()
  }
 
  DMVSLB <- DMVSLB %>% 
    convert_blood_to_plasma()
  
  variables_names <- setdiff(variables_names, c("GLUC_B", "GLUC2H_B"))
}
```

### Keep only IDs that are fasted at baseline
```{r fasted_samples, eval = params_steps$step_2}
if (all(is.na(DMVSLB[, "LBFAST"]))) {
  cat("Fasting information (`LBFAST`) is not available: all individuals are kept and supposed to be fasted at baseline.  \n\n")
  cat("\n")
  DMVSLB.QC0 <- DMVSLB
} else {
  nonFastedSamples <- DMVSLB %>%
    group_by(STUDYID, SUBJID) %>%
    filter(VISIT == "BASELINE") %>%
    filter(!(LBFAST %in% "Y" | is.na(LBFAST))) %>%
    select(STUDYID, SUBJID) %>%
    mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
    ungroup() %>%
    select(ID) %>%
    unlist()

  DMVSLB.QC0 <- DMVSLB %>%
    mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
    filter(!ID %in% nonFastedSamples) %>%
    select(-ID)

  naFastedSamples <- DMVSLB.QC0 %>%
    group_by(STUDYID, SUBJID) %>%
    filter(VISIT == "BASELINE" & is.na(LBFAST)) %>%
    ungroup() %>%
    count() %>%
    `[[`("n")

  cat(paste0("Fasting information (`LBFAST`) is missing for ", format(naFastedSamples, big.mark = ","), " individuals: these individuals are kept and supposed to be fasted at baseline.  \n\n"))
  cat("\n")
}
```

Total individuals available : `r ifelse(params$analysis_step>=2, DMVSLB.QC0 %>% select(STUDYID, SUBJID) %>% distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

### Exclusion of participants with data available from only one time-point
```{r check_samples_with_one_measure, eval = params_steps$step_2}
variables_names_available <- variables_names[!grepl("_NA", variables_names)]
OneTimePointSamples <- DMVSLB.QC0 %>%
  group_by(STUDYID, SUBJID) %>%
  summarise_at(
    .vars = vars(variables_names_available),
    .funs = (function(.x) {sum(!is.na(.x))})
  ) %>%
  filter_at(
    .vars = vars(variables_names_available),
    .vars_predicate = any_vars(. == 1)
  ) %>%
  select(STUDYID, SUBJID) %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  ungroup() %>%
  select(ID) %>%
  unlist()

DMVSLB.QC1 <- DMVSLB.QC0 %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  filter(!ID %in% OneTimePointSamples) %>%
  select(-ID)
```

Total individuals available : `r ifelse(params$analysis_step>=2, DMVSLB.QC1 %>% select(STUDYID, SUBJID) %>% distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

### Exclusion of participants with diabetes at baseline

  * Fasting glucose $\geq$ 7.0 mmol/l (126 mg/dl; 1.26 g/l) => `GLUC`
  * 2–h glucose $\geq$ 11.1 mmol/l (200 mg/dl; 2 g/l) => `GLUC2H`
  * HbA1c $\geq$ 48 mmol/mol (6.5 %)  => `HBA1C`

```{r check_diabetic_baseline, eval = params_steps$step_2}
BaselineDiabetesSamples <- DMVSLB.QC1 %>%
  group_by(STUDYID, SUBJID) %>%
  mutate_at(.vars = vars(grep("GLUC_", variables_names, value = TRUE)), .funs = ~.>=7.0) %>% 
  mutate_at(.vars = vars(grep("HBA1C_", variables_names, value = TRUE)), .funs = ~.>=48) %>% 
  filter(VISIT=="BASELINE") %>%
  filter_at(
    .vars = vars(grep("GLUC_", variables_names, value = TRUE), grep("HBA1C_", variables_names, value = TRUE)),
    .vars_predicate = any_vars(.==TRUE)
  ) %>%
  select(STUDYID, SUBJID) %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  ungroup() %>%
  select(ID) %>%
  unlist()

DMVSLB.QC2 <- DMVSLB.QC1 %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  filter(!ID%in%BaselineDiabetesSamples) %>%
  select(-ID)
```

Total individuals available : `r ifelse(params$analysis_step>=2, DMVSLB.QC2 %>% select(STUDYID, SUBJID) %>% distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

### Exclusion of participants developing diabetes during the study time without informations about medication
```{r check_incident_diabetic_medication, eval = params_steps$step_2}
# Get samples developing diabetes according to definition
FollowUpDiabetesSamples.def <- DMVSLB.QC2 %>%
  group_by(STUDYID, SUBJID) %>%
  mutate_at(.vars = vars(grep("GLUC_", variables_names, value = TRUE)), .funs = ~.>=7.0) %>% 
  mutate_at(.vars = vars(grep("HBA1C_", variables_names, value = TRUE)), .funs = ~.>=48) %>% 
  filter_at(
    .vars = vars(grep("GLUC_", variables_names, value = TRUE), grep("HBA1C_", variables_names, value = TRUE)),
    .vars_predicate = any_vars(.==TRUE)
  ) %>% 
  select(STUDYID, SUBJID) %>%
  distinct() %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  ungroup() %>%
  select(ID) %>%
  unlist()

# Get samples diagnose diabetes during the follow-up
FollowUpDiabetesSamples.diag <- MH %>%
  filter(
    MHTERM %in% c("DIABETES", "TYPE 1 DIABETES", "TYPE 2 DIABETES") & MHOCCUR == "Y"
  ) %>%
  select(STUDYID, SUBJID) %>%
  distinct() %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  ungroup() %>%
  select(ID) %>%
  unlist()

# Get medication information for all samples developing T2D based on definition and diagnostic
CheckMedication <- CM %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  filter(
    ID %in% c(FollowUpDiabetesSamples.def, FollowUpDiabetesSamples.diag)
  ) %>%
  filter(
    CMCAT %in% c("INSULINS AND ANALOGUES", "BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS")
  ) %>%
  group_by(ID, CMCAT) %>%
  summarise(
    CHOCCUR = any(CMOCCUR %in% "Y")
  ) %>%
  ungroup() %>%
  filter(CHOCCUR)

# List samples with 'INSULINS AND ANALOGUES' medication for later exclusion
samplesWithInsulin.ToExclude <- CheckMedication %>%
  filter(CMCAT %in% "INSULINS AND ANALOGUES") %>%
  select(ID) %>%
  unlist()

# List incident diabetic samples with 'BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS'
# and without 'INSULINS AND ANALOGUES' medication
diabeticSamplesWithMedicationInfo.ToKeep <- setdiff(
  (CheckMedication %>%
    filter(CMCAT %in% "BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS") %>%
    select(ID) %>%
    unlist()),
  samplesWithInsulin.ToExclude
)

# List incident diabetic samples without medication information an/or 'INSULINS AND ANALOGUES'
FollowUpDiabetesSamples.ToExclude <- setdiff(
  unique(c(FollowUpDiabetesSamples.def, FollowUpDiabetesSamples.diag)),
  diabeticSamplesWithMedicationInfo.ToKeep
)

# Exclude samples in 'FollowUpDiabetesSamples.ToExclude'
DMVSLB.QC3 <- DMVSLB.QC2 %>%
  mutate(ID = paste(STUDYID, SUBJID, sep = "_")) %>%
  filter(!ID %in% FollowUpDiabetesSamples.ToExclude) %>%
  select(-ID)
```

Total individuals available after QC: `r ifelse(params$analysis_step>=2, DMVSLB.QC3 %>% select(STUDYID, SUBJID) %>% distinct() %>% nrow() %>% format(., big.mark = ","), NA)`


`r if (knitr:::is_latex_output()) {'\\clearpage'}`

# Preliminary modelling

## Summary
The linear mixed model (LMM) is a suitably flexible approach, given that the intervals between data collection points is not uniform between cohorts; the LMM also permits the inclusion of different covariates, as well as unbalanced data within each cohort. 

The LMM can be described as $y_{ij}=\alpha+\alpha_i+\beta t_{ij}+\beta_i t_{ij}+\epsilon_{ij}$, where $y_{ij}$ is a trait measurement for participant $i$ at time $j$ ($j=1,2,\dots$), $\alpha$ and $\beta$ are fixed effects for average intercept and time (slope), respectively.  
$\alpha_i$ and $\beta_i$ are the individual (random) intercept and slope for participant $i$, assumed to be correlated and $\left(\alpha_i, \beta_i\right)\sim \mathcal{N}_2(0,\Sigma)$, i.e. coming from two-dimensional normal distribution. 
$\epsilon_{ij}\sim \mathcal{N}(0,\sigma^2)$ is a random error term.  
Baseline time is set to zero; hence $t$ is the time since baseline.  
To adjust for different covariates (both time invariant and those varying over time) additional parameters can be added to the model.  
To account for the possibility that the baseline trait has an effect on subsequent measurements, one can introduce a binary variable: `1` when baseline measurement and `0` otherwise.

For cohorts with only two time-points, only a random intercept can be fitted; hence, the $\beta_i$ parameter is removed from the model and a random intercept is derived from a one-dimensional normal distribution ($\alpha_i\sim \mathcal{N}(0,\sigma_\alpha^2)$).

For cohorts containing family data, the correlation between family members has to be taken into account. 

> **Mickaël Canouil:** Not working (yet) on family data.


## Code results

Default covariates included in the model are `AGE0`, `SEX0` and `BMI0` (baseline values).  
Additional covariates might be needed depending on the cohort.

```{r preliminary_model_functions, eval = params_steps$step_3}
# function to extract results from lmer functions in a tidy way (one row)
tidyLmer <- function(x) {
  sfit <- coefficients(summary(x))
  colnames(sfit) <- c("ESTIMATE", "SE", "DF", "STAT", "PVALUE")
  rownames(sfit)[grep("Intercept", rownames(sfit))] <- "Intercept"
  return(matrix(
    data = as.vector(sfit),
    nrow = 1,
    dimnames = list(
      NULL,
      apply(expand.grid(rownames(sfit), colnames(sfit)), 1, paste, collapse = ".")
    )
  ))
}

# extract residuals from mixed model and list samples with median plus/minus 3*IQR
getResidualsOutliers <- function(x) {
  rx <- residuals(x)
  return(
    x@frame[names(rx[rx >= median(rx) + 3 * IQR(rx) | rx <= median(rx) - 3 * IQR(rx)]), "SUBJID"]
  )
}
```

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

### First Run

#### Check number of time points
```{r preliminary_first_run_check_number_measures, eval = params_steps$step_3}
nTimePoints <- DMVSLB.QC3 %>%
  select(VISIT) %>%
  distinct() %>%
  nrow()

# Include random slope if more than two time points
if (nTimePoints > 2) {
  formula.rightPart <- ~ 1 + AGE0 + SEX0 + BMI0 + VISIT_YEARS + (1 + VISIT_YEARS | SUBJID)
  cat(paste0("Random intercept and random slope are included in the model (up to ", nTimePoints, " time points available).\n\n"))
  cat("\n")
} else {
  formula.rightPart <- ~ 1 + AGE0 + SEX0 + BMI0 + VISIT_YEARS + (1 | SUBJID)
  cat(paste0("Only a random intercept is included in the model (up to ", nTimePoints, " time points available).\n\n"))
  cat("\n")
}
```

```{r preliminary_first_run, eval = params_steps$step_3}
residuals_outliers <- as.list(rep(NA, length(variables_names))) %>% 
  `names<-`(variables_names)
for (ivariable in variables_names) {
  if (grepl("GLUC_", ivariable)) {
    big_names <- "Glucose"
  }
  if (grepl("GLUC2H_", ivariable)) {
    big_names <- "2-Hour glucose"
  }
  if (grepl("HBA1C_", ivariable)) {
    big_names <- "HbA1c"
  }
  
  cat(paste0("\n\n#### ", big_names, " (`", ivariable, "`)\n"))

  fit.data <- DMVSLB.QC3 %>%
    select(matches(ivariable), AGE0, SEX0, BMI0, VISIT_YEARS, SUBJID, STUDYID)
  
  if (!all(is.na(fit.data[, ivariable]))) {
    fit <- lmer(
      formula = eval(parse(text = paste0('update.formula(formula.rightPart, ', ivariable, '~.)'))),
      data = fit.data
    )
    
    cat("\n##### Trajectories\n\n")
    pTraj <- fit.data %>%
      mutate(
        ID = paste(STUDYID, SUBJID, sep = "_"),
        pT2D = ifelse(
          ID %in% diabeticSamplesWithMedicationInfo.ToKeep,
          "PreDiab",
          "Normo"
        )
      ) %>%
      ggplot(data = ., aes_string(x = "VISIT_YEARS", y = ivariable, colour = "ID")) +
      geom_line() +
      guides(colour = "none") +
      scale_colour_viridis(discrete = TRUE, begin = 0, end = 4 / 5) +
      facet_grid(.~pT2D)
    print(pTraj)
    cat("\n")
    
    
    cat("\n##### Residuals plot\n\n")
    p0 <- plot_grid(
      ggplot(data = data.frame(x = fitted(fit), y = residuals(fit)), aes(x = x, y = y)) +
        geom_point(shape = 21, colour = viridis_pal()(1)) +
        labs(x = "Fitted", y = "Residuals"),
      ggplot(data = data.frame(y = residuals(fit), x = "x"), aes(x = x, y = y)) +
        geom_boxplot(
          shape = 21,
          colour = viridis_pal(begin = 0.5, end = 0.5)(1),
          outlier.shape = 21
        ) +
        geom_hline(
          yintercept = median(residuals(fit)) + 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        geom_hline(
          yintercept = median(residuals(fit)) - 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        labs(y = "Residuals", x = NULL) +
        theme(axis.text.x = element_blank()),
      labels = LETTERS[c(1, 2)],
      align = "hv"
    )
    print(p0)
    cat("\n")
    
    
    residuals_outliers[[ivariable]] <- getResidualsOutliers(fit)
    
    
    cat("\n##### Results for random effect as a matrix\n\n")
    if (nTimePoints > 2) {
      # Compare model with or without random slope (anova)
      fit.random <- anova(
        update(fit, formula = .~. - (1 + VISIT_YEARS | SUBJID) + (1 | SUBJID)),
        fit, refit = FALSE
      ) %>%
        mutate(Mod = c("Mod0", "Mod1")) %>%
        column_to_rownames(var = "Mod") %>%
        as.data.frame()
      mykable(fit.random, pval_cols = grep("Pr(>Chisq)", colnames(fit.random), fixed = TRUE)) %>%
        print()
    } else {
      cat("Not enough time points to test a random slope term.")
      cat("\n")
    }
    
    
    cat("\n##### Results for fixed effect as a matrix\n\n")
    coeff_fit <- summary(fit) %>%
      coefficients() %>%
      as.data.frame()
    
    if (any(grepl("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE))) {
      mykable(coeff_fit, pval_cols = grep("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE)) %>%
        print()
    } else {
      cat("Warning: p-values were not computed by lmerTest, probably due to computational error.")
      cat("\n")
    }
  
    
    cat("\n##### Results for fixed effect as a row\n\n")
    fit.fixed <- tidyLmer(fit) %>%
      as.data.frame()
  
    if (any(grepl("PVALUE", colnames(fit.fixed)))) {  
      mykable(fit.fixed, pval_cols = grep("PVALUE", colnames(fit.fixed))) %>%
        print()
    } else {
      cat("Warning: p-values were not computed by lmerTest, probably due to computational error.")
      cat("\n")
    }
  } else {
    cat(paste0("`", ivariable, "` is not available."))
    cat("\n")
    residuals_outliers[[ivariable]] <- NULL
  }
  
  if (knitr:::is_latex_output()) {cat('\\clearpage'); cat("\n")}
}
```

### Second Run (after residuals check)
```{r preliminary_second_run_qc, eval = params_steps$step_3}
DMVSLB.QC4 <- DMVSLB.QC3 %>%
  filter(!SUBJID%in%unique(unlist(residuals_outliers)))
```

Total individuals available : `r ifelse(params$analysis_step>=3, DMVSLB.QC4 %>% select(STUDYID, SUBJID) %>% distinct() %>% nrow() %>% format(., big.mark = ","), NA)`.

```{r preliminary_second_run, eval = params_steps$step_3}
residuals_outliers <- as.list(rep(NA, length(variables_names))) %>% 
  `names<-`(variables_names)

for (ivariable in variables_names) {
  if (grepl("GLUC_", ivariable)) {
    big_names <- "Glucose"
  }
  if (grepl("GLUC2H_", ivariable)) {
    big_names <- "2-Hour glucose"
  }
  if (grepl("HBA1C_", ivariable)) {
    big_names <- "HbA1c"
  }
  
  cat(paste0("\n\n#### ", big_names, " (`", ivariable, "`)\n"))

  fit.data <- DMVSLB.QC4 %>%
    select(matches(ivariable), AGE0, SEX0, BMI0, VISIT_YEARS, SUBJID, STUDYID)
  
  if (!all(is.na(fit.data[, ivariable]))) {
    fit <- lmer(
      formula = eval(parse(text = paste0('update.formula(formula.rightPart, ', ivariable, '~.)'))),
      data = fit.data
    )
    
    cat("\n##### Trajectories\n\n")
    pTraj <- fit.data %>%
      mutate(
        ID = paste(STUDYID, SUBJID, sep = "_"),
        pT2D = ifelse(
          ID %in% diabeticSamplesWithMedicationInfo.ToKeep,
          "PreDiab",
          "Normo"
        )
      ) %>%
      ggplot(data = ., aes_string(x = "VISIT_YEARS", y = ivariable, colour = "ID")) +
      geom_line() +
      guides(colour = "none") +
      scale_colour_viridis(discrete = TRUE, begin = 0, end = 4 / 5) +
      facet_grid(.~pT2D)
    print(pTraj)
    cat("\n")
    
    
    cat("\n##### Residuals plot\n\n")
    p0 <- plot_grid(
      ggplot(data = data.frame(x = fitted(fit), y = residuals(fit)), aes(x = x, y = y)) +
        geom_point(shape = 21, colour = viridis_pal()(1)) +
        labs(x = "Fitted", y = "Residuals"),
      ggplot(data = data.frame(y = residuals(fit), x = "x"), aes(x = x, y = y)) +
        geom_boxplot(
          shape = 21,
          colour = viridis_pal(begin = 0.5, end = 0.5)(1),
          outlier.shape = 21
        ) +
        geom_hline(
          yintercept = median(residuals(fit)) + 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        geom_hline(
          yintercept = median(residuals(fit)) - 3 * IQR(residuals(fit)),
          linetype = 2,
          colour = viridis_pal(begin = 0.25, end = 0.25)(1)
        ) +
        labs(y = "Residuals", x = NULL) +
        theme(axis.text.x = element_blank()),
      labels = LETTERS[c(1, 2)],
      align = "hv"
    )
    print(p0)
    cat("\n")
    
    
    # residuals_outliers[[ivariable]] <- getResidualsOutliers(fit)
    
    
    cat("\n##### Results for random effect as a matrix\n\n")
    if (nTimePoints > 2) {
      # Compare model with or without random slope (anova)
      fit.random <- anova(
        update(fit, formula = .~. - (1 + VISIT_YEARS | SUBJID) + (1 | SUBJID)),
        fit, refit = FALSE
      ) %>%
        mutate(Mod = c("Mod0", "Mod1")) %>%
        column_to_rownames(var = "Mod") %>%
        as.data.frame()
      mykable(fit.random, pval_cols = grep("Pr(>Chisq)", colnames(fit.random), fixed = TRUE)) %>%
        print()
    } else {
      cat("Not enough time points to test a random slope term.")
      cat("\n")
    }
    
    
    cat("\n##### Results for fixed effect as a matrix\n\n")
    coeff_fit <- summary(fit) %>%
      coefficients() %>%
      as.data.frame()
    
    if (any(grepl("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE))) {
      mykable(coeff_fit, pval_cols = grep("Pr(>|t|)", colnames(coeff_fit), fixed = TRUE)) %>%
        print()
    } else {
      cat("Warning: p-values were not computed by lmerTest, probably due to computational error.")
      cat("\n")
    }
    
    
    cat("\n##### Results for fixed effect as a row\n\n")
    fit.fixed <- tidyLmer(fit) %>%
      as.data.frame()
    
    if (any(grepl("PVALUE", colnames(fit.fixed)))) {
      mykable(fit.fixed, pval_cols = grep("PVALUE", colnames(fit.fixed))) %>%
        print()
    } else {
      cat("Warning: p-values were not computed by lmerTest, probably due to computational error.")
      cat("\n")
    }
  } else {
    cat(paste0("`", ivariable, "` is not available."))
    cat("\n")
    # residuals_outliers[[ivariable]] <- NULL
  }
  
  if (knitr:::is_latex_output()) {cat('\\clearpage'); cat("\n")}
}
```

# Descriptive statistics
```{r display_descriptive_statistics, eval = params_steps$step_3}
# function to compute mean and sd, then paste results for output
computeMeanSD <- function(x, digits = 2) {
  return(paste0(
    round(mean(x, na.rm = TRUE), digits = digits),
    " (",
    round(sd(x, na.rm = TRUE), digits = digits),
    ")"
  ))
}

demoDescriptTable <- DMVSLB.QC4 %>%
  group_by(STUDYID) %>%
  mutate(
    NumberParticipants = format(length(unique(SUBJID)), big.mark = ","),
    MalesPercent = round((sum(SEX0) / length(SEX0)) * 100, digits = 2)
  ) %>%
  group_by(STUDYID, SUBJID) %>%
  mutate(
    NumberMeasures = length(unique(VISIT_YEARS)),
    FollowUpDuration = diff(range(VISIT_YEARS, na.rm = TRUE))
  ) %>%
  filter(VISIT == "BASELINE") %>%
  ungroup() %>%
  group_by(STUDYID) %>%
  (function(.data) {
    full_join(
      x = .data %>% 
        summarise(
          NumberParticipants = unique(NumberParticipants),
          NumberMeasures = computeMeanSD(NumberMeasures, digits = 2),
          FollowUpDuration = computeMeanSD(FollowUpDuration, digits = 2),
          MalesPercent = unique(MalesPercent),
          BaselineAge = computeMeanSD(AGE0, digits = 2),
          BaselineBMI = computeMeanSD(BMI0, digits = 2)
        ),
      y = .data %>% 
        summarise_at(.vars = vars(variables_names), .funs = computeMeanSD) %>% 
        `colnames<-`(c(colnames(.)[1], paste0("Baseline", colnames(.)[-1]))),
      by = "STUDYID"
    )
  }) %>%
  ungroup() %>%
  select(
    STUDYID,
    NumberParticipants, NumberMeasures, FollowUpDuration, MalesPercent,
    BaselineAge, BaselineBMI, everything()
  ) %>%
  t() %>%
  `colnames<-`(.[1, ]) %>%
  `[`(-1, , drop = FALSE)

mykable(demoDescriptTable)
```



`r if (knitr:::is_latex_output()) {'\\clearpage'}`

# Association and interaction analyses

## Summary
To perform GWAS analysis, SNP main effect and SNP x time interaction term are included to the preliminary model above; these parameters are average linear effect of time and SNP effect on the rate change (SNP x time), respectively. 

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

## Code results

### Check available VCF files

Please, provide VCF files in dosage format and check the availability of the imputation quality tag used (e.g. `INFO`).

```{r check_available_vcf, eval = params_steps$step_4}
listVCF <- list.files(path = params$vcf_input_directory, pattern = ".vcf.gz$")
cat(
  paste0(
    "The following VCF files (", length(listVCF), ") are available within the directory path provided: \n\n",
    paste0("  * ", listVCF, collapse = "\n")
  )
)
cat("\n")
```

`r if (knitr:::is_latex_output()) {'\\clearpage'}`

### Prepare and format VCF files

#### Export Rmarkdown parameters in system environment for bash use
```{r export_rmarkdown_parameters, eval = params_steps$step_4}
Sys.setenv(projectName = params$cohort_name)
Sys.setenv(vcfin = params$vcf_input_directory)
Sys.setenv(vcfout = params$output_directory)
Sys.setenv(imputationQualityTag = params$imputation_quality_tag)
Sys.setenv(vcftoolsPath = params$vcftools_binary_path)

cat(
  paste(
    paste0("#!/bin/sh\n\n", "./handleVCF.sh"),
    params$cohort_name,
    params$output_directory,
    params$imputation_quality_tag,
    params$vcftools_binary_path,
    "\n\n"
  ),
  sep = "",
  file = paste0(params$output_directory, "/handleVCF_", params$cohort_name, ".sh")
)
```

#### Format and split VCF using bash and vcftools (needs to be installed)

#### List all VCFs path in a file
```{sh list_vcf, eval = params_steps$step_4}
find $vcfin/*[2][12]*.vcf.gz > $vcfout/vcffilespath.txt
```

##### Manually format VCFs
Shell script can be run from your output directory (`` `r params$output_directory` ``) using the generated command line file (`` `r paste0("handleVCF_", params$cohort_name, ".sh")` ``) and shell script (`handleVCF.sh`, must be located in `` `r params$output_directory` ``).

##### Automatically format VCFs
```{sh format_vcf, eval = params_steps$step_5 & params$format_vcfs, echo = params_steps$step_5 & params$format_vcfs, results = "hide"}
## Description:
## When analysing the SNPs in R (lme4) the scripts crashes due to the amount of SNPs.
## We need to break down the data into smaller pieces.
## In this script we take one vcf file as input (ex chr1).
## Filter out bad SNPs and extact dosage, impute and frequency.
## Author: Thomas Sparsø


## the input arguments are a vcf file (must be gzipped, only one chr)
# projectName=$1
# vcfout=$2
# imputationQualityTag=$3
# vcftoolsPath=$4


echo -e "\n"
echo "Name of Project: $projectName"
echo "Name of imputation quality tag (INFO/*): $imputationQualityTag"



# to format only on chromosome 22 vcfs: $vcfin/22*.vcf.gz
# find $vcfin/*.vcf.gz | while read vcf
cat $vcfout/vcffilespath.txt | while read vcf
do

  base=`basename $vcf`
  echo "name of inputFile: $base"

  ## directory for extraction from vcf (dosage, freq, etc). and for the small vcf files
  chrDir=`basename $vcf .vcf.gz`
  eVCF=$vcfout/$chrDir/extractVCF
  sVCF=$vcfout/$chrDir/smallVCF
  mkdir -p $eVCF
  mkdir -p $sVCF


  ## clean up before we start
  rm -f $eVCF/*
  rm -f $sVCF/*


  ############# step 1: Delete the obviuos problematic SNPs, indels, and rare SNPs
  echo -e "\n"
  echo "Reduce bad SNPs in $base ... (takes a while if many SNPs)"
  $vcftoolsPath/vcftools --gzvcf $vcf \
    --get-INFO $imputationQualityTag \
    --out $eVCF/tmp
  awk '{if($5<0.3) print $1"\t"$2}' $eVCF/tmp.INFO > $eVCF/delme
  $vcftoolsPath/vcftools --gzvcf $vcf \
    --exclude-positions $eVCF/delme \
    --maf 0.01 \
    --remove-indels \
    --remove-filtered-all \
    --recode-INFO-all \
    --recode \
    --stdout | gzip -c > $eVCF/filtered.$base


  ############ step 2: Break down the vcf file into smaller files.
  ############ Make a header and attached the header to all Files
  gunzip -c $eVCF/filtered.$base | head -n 200 | awk '/^#/' > $sVCF/tmpHeader

  ## unzip vcf and keep all but header. Split the files into lines of 1000 and call them pre*
  gunzip -c $eVCF/filtered.$base | awk '!/^#/' |  split - -l1000 $sVCF/pre

  ## loop through the pre*, add the header and zip the file. Save as "small_*.vcf.gz"
  find $sVCF/pre* | while read pathToFile;
  do
    file=`basename $pathToFile`
    cat $sVCF/tmpHeader $sVCF/$file | gzip -c > $sVCF/small_${file}.vcf.gz
  done


  ########### step 3: is DS available?
  ###maybe we should check if dosage is available for all cohorts before we make a script here.



  ########### step 4: Extract dosage, impute, freq from each od the small VCFs
  echo -e "\n"
  echo extract dosage, R2, freq...

  find $sVCF/small* | while read pathToFile
  do
    file=`basename $pathToFile .vcf.gz`

    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --extract-FORMAT-info DS \
      --stdout | gzip -c > $eVCF/$file.DS.gz
      
    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --get-INFO $imputationQualityTag \
      --out $eVCF/$file
      
    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --hardy \
      --out $eVCF/$file
      
    # $vcftoolsPath/vcftools --gzvcf $pathToFile \
    #   --missing-site \
    #   --out $eVCF/$file
      
    $vcftoolsPath/vcftools --gzvcf $pathToFile \
      --freq \
      --out $eVCF/$file
    sed -i s/"{ALLELE:FREQ}"/frq1"\t"frq2/ $eVCF/$file.frq
  done


  ########## step 5: clean up
  rm -f $eVCF/filtered.$base
  rm -f $sVCF/tmpHeader
  rm -f $sVCF/pre*
  rm -f $eVCF/delme
  rm -f $eVCF/tmp.INFO

done
```


`r if (knitr:::is_latex_output()) {'\\clearpage'}`

### Run Mixed Model with imputed genotypes
```{r lmm_genotypes, eval = params_steps$step_6 & params$variants_analysis}
listChrDirectories <- grep(
  pattern = "extractVCF",
  x = list.dirs(params$output_directory, full.names = TRUE),
  value = TRUE
)

for (ichrdirectory in listChrDirectories) {
  message(ichrdirectory)

  # dir.create(gsub("extractVCF", "outputLMM", ichrdirectory), showWarnings = FALSE)
  ichrfilename <- gsub(".*/(.*)/extractVCF", "\\1", ichrdirectory)
  outputLMMdirectory <- paste0(params$output_directory, "/outputLMM/", ichrfilename)
  dir.create(outputLMMdirectory, showWarnings = FALSE, recursive = TRUE)

  ## Read imputed genotypes (dosage file)
  listDosageFile <- list.files(path = ichrdirectory, pattern = ".DS.gz$", full.names = TRUE)
  
  listDosageFile <- listDosageFile[c(1, 2)] # to be removed

  ## Parallelise on chunks
  for (idosagefile in listDosageFile) {
    message(idosagefile)
    chunkDosageFile <- read.table(file = idosagefile, header = TRUE, check.names = FALSE)

    ## Check intersect between phenotypes and genotypes data
    samplesWithPhenoGeno <- intersect(
      unique(DMVSLB.QC4[, "SUBJID"]),
      colnames(chunkDosageFile)[-c(1, 2)]
    )
    DMVSLB.QC5 <- DMVSLB.QC4 %>%
      filter(SUBJID %in% samplesWithPhenoGeno)

    ## Format genotypes
    chunkDosageFile.fmt <- chunkDosageFile[, c("CHROM", "POS", samplesWithPhenoGeno)] %>%
      mutate(SNP = paste(CHROM, POS, sep = "_")) %>%
      select(-CHROM, -POS)
    ### Remove multi-allele SNPs (duplicated chromosome:positition)
    multiAlleleSnps <- chunkDosageFile.fmt[duplicated(chunkDosageFile.fmt[, "SNP"]), "SNP"]
    chunkDosageFile.fmt <- chunkDosageFile.fmt %>%
      filter(!SNP %in% multiAlleleSnps) %>%
      column_to_rownames(var = "SNP") %>%
      t()

    ## Combine phenotypes and genotypes
    pheGeno.data <- merge(
      x = DMVSLB.QC5,
      y = chunkDosageFile.fmt,
      by.x = "SUBJID",
      by.y = "row.names"
    )

    ## Run Mixed Model by SNP
    resLMM.snp <- mclapply(
      colnames(chunkDosageFile.fmt),
      mc.cores = params$n_cpu,
      mc.preschedule = FALSE,
      function(isnp) {
        # print(isnp)
        
        results_lmm <- as.list(rep(NA, length(variables_names))) %>% 
          `names<-`(variables_names)
        for (ivariable in variables_names) {
          if (!all(is.na(pheGeno.data[, ivariable]))) {
            fit.gluc <- lmer(
              formula = eval(parse(text = paste0(
                "update.formula(formula.rightPart, ", ivariable, "~.+`", isnp, "`*VISIT_YEARS)"
              ))),
              data = pheGeno.data
            )
            results_lmm[[ivariable]] <- cbind.data.frame(
              TRAIT = ivariable,
              SNP = isnp,
              tidyLmer(fit.gluc)
            ) %>% 
            `colnames<-`(gsub(
              pattern = paste0("`", isnp, "`"),
              replacement = "SNP",
              x = colnames(.),
              fixed = TRUE
            ))
          } else {
            results_lmm[[ivariable]] <- NULL
          }
        }

        res_all <- do.call("rbind", results_lmm)
        return(res_all)
      }
    )
    listerrors <- sapply(resLMM.snp, is, class2 = "try-error")

    cat(
      colnames(chunkDosageFile.fmt)[listerrors],
      sep = "\n",
      file = paste0(outputLMMdirectory, "/", gsub(".*/([^.]*).*", "\\1", idosagefile), ".log")
    )
    resLMM.snp <- resLMM.snp[!listerrors]

    annot_chunk <- full_join(
      x = read_tsv(gsub(".DS.gz", ".frq", idosagefile)),
      y = read_tsv(gsub(".DS.gz", ".hwe", idosagefile)), 
      by = c("CHROM" = "CHR", "POS" = "POS")
    ) %>% 
      full_join(
        x = .,
        y = read_tsv(gsub(".DS.gz", ".INFO", idosagefile)) %>% 
          select(-REF, -ALT), 
        by = c("CHROM" = "CHROM", "POS" = "POS")
      ) %>%
        mutate(SNP = paste(CHROM, POS, sep = "_"))
    
    resLMM.chunk <- merge(
      x = annot_chunk,
      y = do.call("rbind", resLMM.snp),
      by = "SNP"
    )

    ## Write results
    for (ivariable in variables_names) {
      if (!grepl("_NA", ivariable)) {
        dir.create(paste0(outputLMMdirectory, "/", ivariable), showWarnings = FALSE)
        output_filename <- paste0(
          paste0(outputLMMdirectory, "/", ivariable),
          "/", ivariable, "_",
          gsub(".*/([^.]*).*", "\\1", idosagefile),
          ".csv"
        )
        write_csv(
          x = filter(resLMM.chunk, TRAIT == ivariable),
          path = output_filename
        )
      }
    }
  }
}
```

```{r lmm_genotypes_ouput, eval = params_steps$step_6, include = params_steps$step_6}
listChrDirectories <- grep(
  pattern = "extractVCF", 
  x = list.dirs(params$output_directory, full.names = TRUE), 
  value = TRUE
)
grep("22", listChrDirectories, value = TRUE) %>% 
  gsub(".*/(.*)/extractVCF", "\\1", .) %>% 
  paste0(params$output_directory, "/outputLMM/", ., "/", variables_names[1], "/") %>% 
  list.files(full.names = TRUE) %>% 
  `[`(1) %>% 
  read.csv(file = ., header = TRUE, nrows = 20) %>% 
  mutate_at(.vars = vars(contains("PVALUE")), .funs = funs(format_pval)) %>% 
  rmarkdown:::print.paged_df()
``` 



`r if (knitr:::is_latex_output()) {'\\clearpage'}`

## Output tree structure
```{r directory_structure, eval = params_steps$step_7, results = "markup"}
dir_tree <- c(
  list.files(path = params$output_directory, pattern = "^22.*", full.names = TRUE) %>%
    list.files(full.names = TRUE) %>%
    sapply(., list.files, pattern = "preaa", full.names = TRUE),
  list.files(path = params$output_directory, pattern = "outputLMM", full.names = TRUE) %>%
    list.files(pattern = "22", full.names = TRUE) %>%
    list.files(full.names = TRUE) %>%
    gsub("small_pre.*.log", "small_preaa.log", .) %>% 
    unique() %>% 
    sapply(., function(i) {
      tmp <- list.files(i, pattern = "preaa", full.names = TRUE)
      return(ifelse(length(tmp) != 0, tmp, i))
    }) %>% 
    gsub("22", "CHR*", ., fixed = TRUE),
  list.files(path = params$output_directory, pattern = "vcffilespath.txt", full.names = TRUE),
  list.files(path = params$output_directory, pattern = paste0("handleVCF_", params$cohort_name, ".sh"), full.names = TRUE)
) %>%
  unlist() %>%
  gsub(params$output_directory, paste0("/", params$cohort_name), .) %>%
  gsub("22", "CHR*", ., fixed = TRUE) %>%
  data.frame(pathString = .) %>%
  as.Node()

dir_tree %>%
  capture.output() %>%
  `[`(-1) %>%
  sapply(., paste0, "\n") %>%
  paste(collapse = "") %>%
  cat()
```


`r if (knitr:::is_latex_output()) {'\\clearpage'}`


